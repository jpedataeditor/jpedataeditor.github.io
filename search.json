[
  {
    "objectID": "replicate.html",
    "href": "replicate.html",
    "title": "Replicate/Reproduce papers published at the EJ",
    "section": "",
    "text": "Looking for reproducible papers to reproduce or replicate? The Economic Journal started publishing the replication packages along with the papers on the Journalâ€™s website a long time ago. Starting December 2019, when the first Data Editor was appointed, these packages went through reproducibility checks. Since April 2021, all replication packages are published at the Economic Journalâ€™s community of Zenodo:"
  },
  {
    "objectID": "best.html",
    "href": "best.html",
    "title": "Best Practices for Replication Packages",
    "section": "",
    "text": "Data Editors Collaborate\n\n\n\nThe Data Editors of the American Economic Association (Lars Vilhuber) the Review of Economic Studies (MiklÃ³s Koren), the Canadian Journal of Economics (Marie Connolly), the Econometric Society (Joan Llull) and the Economic Journal and Econometrics Journal (Florian Oswald) are coordinating reproduciblity requirements and guidelines across different journals. An example of this cooperation is this common guidance by Social Science Data Editors, and parts of the below list.\nThere is a set of practices that are strongly recommended for all replication packages. The following list includes some of them:"
  },
  {
    "objectID": "best.html#folder-structure",
    "href": "best.html#folder-structure",
    "title": "Best Practices for Replication Packages",
    "section": "Folder Structure",
    "text": "Folder Structure\n\nWe are aware that research happens in haphazard ways sometimes, without any time to waste on seemingly irrelevant housekeeping tasks. We encourage you nevertheless to try and impose a rigid folder structure on your research project from day one, when concerns about a replication package might still be far away - some folder could even remain empty for a while, but thatâ€™s ok! You will save a lot of time later on. Here are two examples:\n\n\n\n\nGood.\n\nMeaningful sub directories\ntop level README\ncode/data/output are separated\n\n.\nâ”œâ”€â”€ README.md\nâ”œâ”€â”€ code\nâ”‚Â Â  â”œâ”€â”€ R\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ 0-install.R\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ 1-main.R\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ 2-figure2.R\nâ”‚Â Â  â”‚Â Â  â””â”€â”€ 3-table2.R\nâ”‚Â Â  â”œâ”€â”€ stata\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ 1-main.do\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ 2-read_raw.do\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ 3-figure1.do\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ 4-figure2.do\nâ”‚Â Â  â”‚Â Â  â””â”€â”€ 5-table1.do\nâ”‚Â Â  â””â”€â”€ tex\nâ”‚Â Â      â”œâ”€â”€ appendix.tex\nâ”‚Â Â      â””â”€â”€ main.tex\nâ”œâ”€â”€ data\nâ”‚Â Â  â”œâ”€â”€ processed\nâ”‚Â Â  â””â”€â”€ raw\nâ””â”€â”€ output\n    â”œâ”€â”€ plots\n    â””â”€â”€ tables\nNotice how this example includes tex/main.tex which will produce the final product. The code folder would contain all the source code needed to produce everything in the paper, and could be placed under version control. Notice also that the content of output/ could be erased without problems - all required inputs are separated and could regenerate all results immediately.\n\n\n\n\n\nNot So Good.\n\nSub directories are not helpful\nFile names are confusing\nno README\ncode/data/output are not separated\n\n.\nâ”œâ”€â”€ 20211107ext_2v1.do\nâ”œâ”€â”€ 20220120ext_2v1.do\nâ”œâ”€â”€ 20221101wave1.dta\nâ”œâ”€â”€ james\nâ”‚Â Â  â””â”€â”€ NLSY97\nâ”‚Â Â      â””â”€â”€ nlsy97_v2.do\nâ”œâ”€â”€ mary\nâ”‚Â Â  â””â”€â”€ NLSY97\nâ”‚Â Â      â””â”€â”€ nlsy97.do\nâ”œâ”€â”€ matlab_fortran\nâ”‚Â Â  â”œâ”€â”€ graphs\nâ”‚Â Â  â”œâ”€â”€ sensitivity1\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ data.xlsx\nâ”‚Â Â  â”‚Â Â  â”œâ”€â”€ good_version.do\nâ”‚Â Â  â”‚Â Â  â””â”€â”€ script.m\nâ”‚Â Â  â””â”€â”€ sensitivity2\nâ”‚Â Â      â”œâ”€â”€ models.f90\nâ”‚Â Â      â”œâ”€â”€ models.mod\nâ”‚Â Â      â””â”€â”€ nrtype.f90\nâ”œâ”€â”€ readme.do\nâ”œâ”€â”€ scatter1.eps\nâ”œâ”€â”€ scatter1_1.eps\nâ”œâ”€â”€ scatter1_2.eps\nâ”œâ”€â”€ ts.eps\nâ”œâ”€â”€ wave1.dta\nâ””â”€â”€ wave2.dta\nâ””â”€â”€ wave2regs.dta\nâ””â”€â”€ wave2regs2.dta"
  },
  {
    "objectID": "best.html#data",
    "href": "best.html#data",
    "title": "Best Practices for Replication Packages",
    "section": "Data",
    "text": "Data\n\nAlways keep your raw data intact (i.e.Â read-only). Generate separate analysis datasets to perform analysis. After you copied your raw data into the package (rawdata folder), set to read only. Look here for windows tips to set read-only, on *nix systems itâ€™s a\nchmod 444 rawdata\nDatasets change over time, keep a record of the date and versions you obtained. It might be difficult to obtain it in the future."
  },
  {
    "objectID": "best.html#code",
    "href": "best.html#code",
    "title": "Best Practices for Replication Packages",
    "section": "Code",
    "text": "Code\n\nGenerate your analysis data using programs, many journals require you to submit them.\nSeparate code, data and outputs in your directory structure. This will facilitate (i) keeping versions of your code, and (ii) producing a replication package.\nStronlgy consider the benefits of version control for the reproducibility of your research. Click here for a tutorial.\nUse programs/scripts as opposed to command-line instructions!\nDesign your code to be run all at once, and not section by section. Create a master file that calls all other subsidiary files.\nSet the paths only once and at the top of the master-file, and then use either relative paths or global variables, so that users donâ€™t have to change the paths in multiple parts of your code.\nWhenever possible, write paths in a way that is compatible across different operating systems. For example, in Stata, always use forward slashes / to separate directories, even if you use Windows.\nIf you are using software which requires compilation of source code into executables (e.g.Â Fortran, C, etc.), please use make files (or else make sure you provide very detailed instructions on how to compile the different files - we accept bash shell scripts).\nName your files in a wise manner. For example, if your output generates tables and figures as new files, give them names that easily identify them. Also, name your master file as â€œMainâ€, â€œMasterâ€ or something similar.\nUse sub-folders when your package includes a lot of files. Make sure that your package includes all relevant folders, even empty folders that will be filled with the outputs from the program."
  },
  {
    "objectID": "best.html#output",
    "href": "best.html#output",
    "title": "Best Practices for Replication Packages",
    "section": "Output",
    "text": "Output\n\nUse log-files and write to disk. Make sure that your code stores the output (both tables and figures) as files on disk (in subdirectory outputs/) as opposed to only showing it on screen while you are executing it.\nMake your code produce all tables and figures as they appear in the manuscript: you will save a lot of time! We recommend splitting your code into small subunits, each of which produce a dedicated output, for instance a function figure1() which would produce and save the file outputs/figure1.pdf in your package, where outputs/figure1.pdf is included via \\input{outputs/figure1.pdf} in the \\(\\LaTeX\\) source code of your paper as as Figure 1! Of course the same holds for tables and other output. You could then include the following table in your README, greatly helping our replicators (and yourself ğŸ˜‰):\n\n\n\nOutput in Paper\nOutput in Package\nScript/Program to execute\n\n\n\n\nTable 1\noutputs/tables/table1.tex\ncode/table1.do\n\n\nFigure 1\noutputs/plots/figure1.pdf\ncode/figure1.do\n\n\nFigure 2\noutputs/plots/figure2.pdf\ncode/figure2.do\n\n\n\nRun your codes from the replication folder before you submit and make sure it runs and all your results are reproduced - ideally on another machine!\nMake sure to delete all expected output from the package before you run it, so you can be sure that all output was actually produced.\nIdeally, your submitted paper (your \\(\\LaTeX\\) file which produces it) should depend on the output of your replication package, so that if a piece of output is missing, the paper cannot be compiled (or you would quickly spot the mistake).\nHelp us by submitting your package without any expected output, i.e.Â with an empty folder outputs/."
  },
  {
    "objectID": "package.html",
    "href": "package.html",
    "title": "Prepare and Submit your Replication Package",
    "section": "",
    "text": "After your Managing Editor conditionally accepts your paper (and before she sees your final response and proceeds to final acceptance) your paper will go through reproducibility and anti-plagiarism checks. It is important that you carefully follow the instructions below to ensure that your paper and your replication package are not mishandled. This page provides you with detailed information that will help you preparing your replication package. Read it carefully before you submit!"
  },
  {
    "objectID": "package.html#sec-prelims",
    "href": "package.html#sec-prelims",
    "title": "Prepare and Submit your Replication Package",
    "section": "1 Preliminaries",
    "text": "1 Preliminaries\nYou are requested to submit a single zip file with the following folder structure (please name your folders in this exact way! Notice there should be no spaces in folder names, and no capital letters). In short, the content of your zip file looks as follows:\nâ”œâ”€â”€ 1-paper\nâ”œâ”€â”€ 2-appendices\nâ”œâ”€â”€ 3-replication-package.zip\nâ””â”€â”€ 4-confidential-data-not-for-publication.zip  (Optional)\n\n\n\n\n\n\nFolders 3 and 4 are in zip format!\n\n\n\n\nBoth folder 3 and folder 4 are zip archives.\nOnly include folder 4 with restricted data if an exemption to the Data and Code Availability Policy has been granted to you and you are providing the replication team with temporary access to the data; all codes and unrestricted data should go to folder 3.\n\n\n\nFor folders 1 and 2, please refer to the Economic Journalâ€™s General Instructions to Authors and Guide for Accepted Authors and carefully follow the instructions indicated there. In the lines below, you will find specific guidelines about folder 3 and, if you were granted a data exemption at the time of first submission (see here, here, and here for details), also folder 4.\n\n\n\n\n\n\nSign and Submit Checklist â˜‘\n\n\n\nAlong with your package, you are requested to download, fill, sign and submit this checklist, which refers to the content of the package below"
  },
  {
    "objectID": "package.html#contents-of-replication-package",
    "href": "package.html#contents-of-replication-package",
    "title": "Prepare and Submit your Replication Package",
    "section": "2 Contents of Replication Package",
    "text": "2 Contents of Replication Package\nAs indicated in the journalâ€™s Data and Code Availability Policy all packages should include the following information:\n\nA README file in PDF format (README.pdf). We strongly recommend using this template. You may find in this web app a convenient tool to create your README file.\nThe raw datasets used in the paper and online appendices, including a complete, transparent and precise documentation describing all variables. You can additionally provide the analysis data if this is helpful, but they are not required if the raw data are provided.\nIf you were granted a data exemption at the time of first submission (see here, here, and here for details), you should either provide the replication team with temporary access to the data for the sole purpose of performing the reproducibility checks, or you should submit a synthetic/simulated dataset that allows running the code and produce all outputs in the paper and appendices, even if the results do not match those in the paper. If you can provide temporary access but you cannot share the data in the 4-confidential-data-not-for-publication.zip folder, please contact the Data Editor at jpe.dataeditor@gmail.com to arrange an alternative access method. The content of this folder will be destroyed after the reproducibility checks are completed. All replicators and the Data Editor have signed confidentiality agreements that protect your submission.\nBoth the data cleaning codes and the analysis codes that produce all reproducible outputs reported in the article, appendix, and online appendices (including figures, tables, and numbers reported in the text). If some results are produced without scripts (e.g.Â ArcGIS maps), the README file should include step-by-step very detailed instructions on how to produce that output. In case of simulation/Monte Carlo studies, the authors are requested to set a seed so that the exact numbers that are reported can be obtained.\nIf data are provided in proprietary format (e.g.Â Stataâ€™s .dta), a copy of the data in non-proprietary format (e.g.Â ASCII, .csv).\n\nExperimental papers should additionally include the following PDF documents (if these files are part of the paper or of an appendix, copy them again in a separate document and include them in the replication package):\n\nA document outlining the design of the experiment.\nA copy of the instructions given to participants, in both the original language and an English translation.\nInformation on the selection and eligibility of participants.\nA PDF copy of the Institutional Review Board (IRB) approval of one of the authorsâ€™ institutions (IRB approval number, date, name of the institution) or an explicit mention that an exemption has been granted by the Editorial Board."
  },
  {
    "objectID": "package.html#the-readme-file",
    "href": "package.html#the-readme-file",
    "title": "Prepare and Submit your Replication Package",
    "section": "3 The README File",
    "text": "3 The README File\nThe README file should provide enough instructions so that all users (level of an advanced PhD student and above) can reproduce all the results in the paper in a reasonable amount of time and without problems. We strongly recommend using this template.You may find in this web app a convenient tool to create your README file. The minimum required information includes:\n\nA verbal description of the content of the package (datasets, programs, folders, etc.)\nData Availability Statement: precise indications on how the data were obtained, including required registrations, memberships, application procedures, monetary cost, or other qualifications, and, if applicable, URL to download them (which is typically part of the data citation).\nThe following Statement about Rights:\n\nI certify that the author(s) of the manuscript have legitimate access to and permission to use the data used in this manuscript.\nI certify that the author(s) of the manuscript have documented permission to redistribute/publish the data contained within this replication package. Appropriate permission are documented in the LICENSE.txt file (if applicable).\n\nPrecise instructions on how to run the code.\nIndications on where each piece of output is saved or displayed. (See best practices below)\nSoftware requirements, including the software version and operating system used by the authors.\nAll packages and libraries that need to be installed to run the code and a clear indication on how to obtain them.\nExpected running time (even if it is a few seconds). When relevant, include the hardware that the estimated time refers to.\nData citations: all datasets used in the paper (with no exceptions) should be listed in the references section of the paper in the same way that we cite other papers, and a copy of these citations should appear in a dedicated section of the ReadMe file. You can find some examples here"
  },
  {
    "objectID": "package.html#data-citations",
    "href": "package.html#data-citations",
    "title": "Prepare and Submit your Replication Package",
    "section": "4 Data Citations",
    "text": "4 Data Citations\nAll datasets used in the paper (with no exceptions) should be listed in the references section of the paper in the same way that we cite other papers, and a copy of these citations should appear in a dedicated section of the README file.\nIf the data used in the study is part of the replication package of another paper, both the paper and the replication package should be cited.\n\n\n\n\n\n\nData Citations Are Important!\n\n\n\nEven commonly used datasets should be cited (in fact, funding of public and private institutions that make datasets available, even the most widely used ones, crucially depends on data citations!).\n\n\nMore specific guidance, and examples, on data citations is available here."
  },
  {
    "objectID": "package.html#best-practices",
    "href": "package.html#best-practices",
    "title": "Prepare and Submit your Replication Package",
    "section": "5 Best Practices",
    "text": "5 Best Practices\nWe do not require you to adhere to a particular structure within your folders 3-replication-package.zip and 4-confidential-data-not-for-publication.zip, as long as the content is clearly structured. We recommend at a minimum to keep code, data and output separated. This and other tips for best practice on how to structure your package can be found here."
  },
  {
    "objectID": "package.html#submitting-your-package",
    "href": "package.html#submitting-your-package",
    "title": "Prepare and Submit your Replication Package",
    "section": "6 Submitting Your Package",
    "text": "6 Submitting Your Package\nYou will be invited to submit your package via an upload link by the Data Editor. This invitation will be generated after you have submitted the following items via The EJ Editorial Express as a resubmission of your paper:\n\n1-paper (see SectionÂ 1)\n2-appendix (see SectionÂ 1)\nSigned and dated checklist.pdf\n\nNotice that you will submit 1-paper and 2-appendix twice, once on Editorial Express to trigger the invitation link, and once as part of your replication package (see SectionÂ 1).\nA few days after you submitted the package (in most of the cases, within two weeks) you will be contacted by the Data Editor with the outcome of the reproducibility checks, regardless of whether the checks were successful or there are modifications to be made. Please add jpe.dataeditor@gmail.com and ej_foswald@editorialexpress.com to your safe contacts to avoid that the Data Editorâ€™s messages go to spam!\nIf you need to implement modifications of your package, you will be instructed to do so in the Data Editorâ€™s response. You will iterate with the Data Editor until the reproducibility checks are satisfactorily concluded."
  },
  {
    "objectID": "package.html#after-the-reproducibility-checks-are-completed-publish-your-package",
    "href": "package.html#after-the-reproducibility-checks-are-completed-publish-your-package",
    "title": "Prepare and Submit your Replication Package",
    "section": "7 After the reproducibility checks are completed: publish your package!",
    "text": "7 After the reproducibility checks are completed: publish your package!\nOnce the reproducibility checks are concluded, and upon invitation of the Data Editor, you will be requested to perform a final step: publish your replication package at the Economic Journalâ€™s community of Zenodo. To do so, you need to do the following:\n\nSign up here for a free zenodo account, if you donâ€™t have one already.\nGo to the Economic Journalâ€™s community of Zenodo at ?var:jpe.zenodo.\nStart a new upload within the community using the top-right green button in the below figure. \nUpload the zip compressed version of your replication package (i.e.Â the exact same archive 3-replication-package.zip you sent us in your final iteration of the replication package). Drag-and-drop the zip file to upload it, as shown below. Make sure you only publish the replication package and not the paper or online appendices. Especially, do not publish the content of the 4-confidential-data-not-for-publication.zip folder!\nAfter your upload completes, indicate that you do not have a DOI for this package already, but that you want to Get a DOI now! \nFill in the required metadata:\n\nResource type: Software or Dataset (what you find more applicable).\nPublication date: leave the default todayâ€™s date.\nTitle: Replication package for: â€œ{full title of your manuscript}â€.\nAuthors: Typically the same authors as the manuscript, but you can add others who have contributed significantly to the code you are uploading, such as research assistants (in that case, you are making them coauthors of your replication package, but not of the paper).\nDescription: write a full citation to your manuscript as a description of what the replication package contains.\n\nUse the default license Creative Commons Attribution 4.0 International\nFeel free to fill in any additional meta data, but nothing more is required from our side.\nFinally, click submit for review top right of the page, as illustrated in the figure below. This action will notify the Data Editor of your new upload. We will then check the digital fingerprint of your package against what we have on file, and accept your package into our community."
  },
  {
    "objectID": "before.html",
    "href": "before.html",
    "title": "Before you submit your paper for the first time",
    "section": "",
    "text": "Read here about our Data and Code Availability Policy (DCAP) and make sure you comply with all requirements before you submit the paper for the first time. Check the cases in which exemptions to the policy can be granted and the procedures to obtain them. If you donâ€™t request the exemption at the time of first submission, you will not be able to do it later! Also, there may still be time to gain some insights from our best practice for reproducibility recommendations before you submit."
  },
  {
    "objectID": "before.html#data-and-code-availability-policy",
    "href": "before.html#data-and-code-availability-policy",
    "title": "Before you submit your paper for the first time",
    "section": "Data and Code Availability Policy",
    "text": "Data and Code Availability Policy\n\n\n\n\n\n\nOfficial Policy at EJ\n\n\n\nThis is a reproduction of the official Data and Code Availability Policy of the Economic Journal, which can be found here. In case of discrepancy, the official policy always prevails to the reproduction presented here.\n\n\nThe Economic Journal requires authors of empirical, experimental or numerical papers to provide documentation of how their results were obtained in sufficient detail and accuracy to allow their results to be replicated. When you submit a paper for consideration, you will be asked to confirm that you are willing to comply with this policy. It is essential that you request a data exemption at the point of first submission if you face any restrictions that prevent you from publishing your data or, in general, from complying with any of the provisions of this policy. More details on this process are provided below.\n\n\n\n\n\n\nWhen Will my Paper be Accepted for Publication?\n\n\n\nYour paper will be accepted for final publication only after the results have been checked for reproducibility.\n\n\nOur mission is to conduct the reproducibility checks as fast as possible. Please read the information on this website carefully, so we can achieve this goal. Please, also note the following warning:\n\n\n\n\n\n\nWarning\n\n\n\nThe editorial board of the Economic Journal reserves the right to refuse publication of papers whose authors do not comply with the requirements set out in detail below for each type of paper.\n\n\nOnce the paper is accepted for publication, the replication package will be posted on the journalâ€™s repository at zenodo.org and it will be linked with the paper. Alternative repositories may be acceptable as long as they are considered â€œtrustedâ€ by the journal. Submission on such online repositories indicates that the authors license users to download, copy, and modify this material. Users of the material must acknowledge all authors as the original creators and cite both the replication package and the paper accordingly.\n\n\n\n\n\n\nInstructions for Replication Package\n\n\n\nPlease follow precise instructions on how to structure your replication package here."
  },
  {
    "objectID": "before.html#apply-to-exemptions-to-the-data-and-code-availability-policy",
    "href": "before.html#apply-to-exemptions-to-the-data-and-code-availability-policy",
    "title": "Before you submit your paper for the first time",
    "section": "Apply to exemptions to the Data and Code Availability Policy",
    "text": "Apply to exemptions to the Data and Code Availability Policy\nIf you are not able to comply with some of the aspects of the Data and Code Availability Policy (e.g.Â because you are using restricted-access data or you cannot obtain permission to re-publish the data), you should request an exemption at the time of first submission of your paper. You can find a set of Frequently Asked Questions about the situations under which you can or cannot apply to an exemption to the data and code availability policy here.\nIf you want to request a Data Exemption, you need to select the second option for the Data Policy box during your submission process at the Editorial Express platform, as illustrated in figure FigureÂ 1:\n\n\n\n\n\n\nFigureÂ 1: Data Policy Exemption\n\n\n\nAdditionally, attach a Cover Letter along with your paper in which you indicate the reasons why you believe you are entitled to an exemption to our data and code availability policy.\nOnce the paper is submitted, the Managing Editor will analyze whether (i) there are enough grounds to grant the exemption and (ii) the exemption or the nature of the data limits the interest of the paper. Based on her assessment of these two points, she will make one of the following decisions: (a) move forward with the process, sending your paper to referees, (b) summarily reject your paper, or (c) contact you asking to provide additional information, documentation, or any other requirement that she needs to assess the suitability of the requested exemption. The exemptions are tacitly granted by choosing option (a).\nOnce your paper is conditionally accepted, you will be requested to supply your replication package according to the guidelines specified here on this website. If an exemption to the Data and Code Availability Policy was granted, you will be requested to either provide the Data Editor (and, by extension, to the team of replicators) with temporary access to the data affected by the exemption for the sole purpose of implementing the reproducibility checks. Alternatively, when granting temporary access to the restricted data is not possible, you will be required to include in your package a synthetic or simulated dataset that allows users to run the code and check that it produces all outputs from the paper (and appendices), even if the results do not match those in the paper. You can find a set of FAQs questions about how to proceed with the replication package when an exemption to the Data and Code Availability Policy has been granted here."
  },
  {
    "objectID": "posts/20240505-stataversions/index.html",
    "href": "posts/20240505-stataversions/index.html",
    "title": "STATA Versioning",
    "section": "",
    "text": "This post is the first in a series where we want to analyse the behaviour of STATA in terms of cross-version reproducibility of results. In the current post, we will see inconsistent results for built-in STATA commands across versions, in a future post I plan to illlustrate problematic interactions with user-contributed code in the form of so-called .ado files (I will refer to those as packages). We will draw on real-world examples in the form of replication packages published together with academic papers in the Economic Journal. We will perform computational experiments by running identical code and data with different versions of STATA.\nThe starting point of this exploration is a blog post by the president of StataCorp from 2019 (with a similar message on the STATA website):\nWe will encounter below one example where we found behaviour which is incompatible with this statement. The aim of this post is not to discredit STATA in any way, but to provide hopefully useful advice on how to avoid distributing unreproducible code. In general, there is nothing which would make STATA better or worse suited to achieve reproducibility, and in this sense I humbly disagree with the above statement. Each language presents its own set of challenges, and being aware of those goes a long way. We reserve a comparison of computing languages in terms of being helpful to writing reproducible code for another occasion."
  },
  {
    "objectID": "posts/20240505-stataversions/index.html#stata-version-x-command",
    "href": "posts/20240505-stataversions/index.html#stata-version-x-command",
    "title": "STATA Versioning",
    "section": "Stata version x Command",
    "text": "Stata version x Command\nSTATA has a command version x which, if called, will mimick the STATA interpreter version x. The entry for help version gives a list of all known changes in behaviour if one sets version x, relative to the current version. The fact that this works is on the one hand nothing but remarkable - the code base of STATA must have changed considerably over the last few decades, surely countless bugs must have been fixed, etc, therefore ensuring that this works must require tremendous effort; on the other hand, it is obvious that version x does not replace the currently running STATA binary with the one of previous STATA version x, so any interactions of that binary with the current computing environment (OS, support libraries etc) could lead to unexpected behaviour. Indeed, we will document such behaviour below.\n\n\n\n\n\n\nData Editors do not care about backward compatibility\n\n\n\nIn general, Data Editors would not require that your code needs to be reproducible with all versions of STATA; quite on the contrary, we want a very specific description of the required environment. Another aim of this post is thus to clarify some (unexpected) effects of the version command, and to counter the belief that setting version will guarantee cross version reproducibility."
  },
  {
    "objectID": "posts/20240505-stataversions/index.html#case-study-xporegress-in-burchardi-et-al-ej-2024",
    "href": "posts/20240505-stataversions/index.html#case-study-xporegress-in-burchardi-et-al-ej-2024",
    "title": "STATA Versioning",
    "section": "Case Study: xporegress in Burchardi et al (EJ 2024)",
    "text": "Case Study: xporegress in Burchardi et al (EJ 2024)\n\nWe found different results for xporegress across STATA versions 16 and v 18 while checking the Burchardi et al (EJ 2024) paper. xporegress is a built-in STATA command.\nNotice we donâ€™t know whether there is anything wrong in xporegress per se, or whether some other aspect of STATA code changed in a way which leads to different results across both verions. We are also agnostic about whether the authors were writing code in any way incompatible with STATA version 18, because:\nTo us, this is irrelevant, as we want to be able to rely on the promise embedded in version 16 solving all issues. The authors set version 16, as well as all required random seeds, in the correct fashion.\n\n\n\n\n\n\n\nğŸ† Data Editor Award for Excellent Collaboration\n\n\n\nThe Burchardi et al package features high quality of code and exceptional collaboration on behalf of the authors. All results replicate exactly on STATA version 16, as indicated in their package readme. They were the first to point out the issue with xporegress to me. Thanks to them! ğŸ¤\n\n\n\nStep 1: Safe Environment via docker\n\nWe want to minimize the risk that anything in our findings is driven by my local STATA installation, and its interaction with my OS. A good solution to this is a containerized environment, for example via docker.\nWe want to have 2 docker containers with version 16 and 18 respectively. We basically want to test the effect of the version 16 command on the stata 18 binary.\nThe dedicated repository of docker images provided by the AEA Data Editor Lars Vilhuber is going to be very helpful here. The prebuilt docker images for different stata versions are available here on dockerhub.\n\nWe can run STATA 16 and STATA 18 as if we had two separate machines inside an isolated environment (a container) on our own computer.\nNotice that there are no user contributed packages installed into those containers. Furthermore, Burchardi et al provide .ado files for add-on packages with their code. So, we have a clean slate.\n\n\n\n\nStep 2: Code to Run Experiment\nTo minimize further mistakes from manually handling code and results, I wrote some julia code which is available here. It downloads the Burchardi et al package from zenodo.org, unpacks it, modifies it slightly (so that it only produces the required appendix table B8 where the discrepancy arises), and then launches the respective STATA containers with the identical code and data; first version 16, where results correspond exactly to the paper, and then version 18, where they do not. The point being, given the promise contained in the version 16 command, results should correspond across versions.\nIf you follow instructions contained therein, you will see the following output in your terminal:\nfloswald@PTL11077 ~/g/E/b/stataversion (main)&gt; julia --project=. runblog.jl\n\n[ Info: downloading record Burchardi\n[ Info: content of /Users/floswald/git/EJData/blogs/stataversion/Burchardi/3-replication-package\n[\".DS_Store\", \"Code\", \"Data\", \"Materials\", \"Output\", \"README.pdf\"]\n[ Info: done downloading\n[ Info: run with stata 16\n[ Info: STATA version 16, docker IMG tag 2023-06-13\nWARNING: The requested image's platform (linux/amd64) does not match the detected host platform (linux/arm64/v8) and no specific platform was requested\n[ Info: renaming /Users/floswald/git/EJData/blogs/stataversion/Burchardi/3-replication-package/Output/Tables/DEMED_AppendixTableB8_dummy.tex\n[ Info: renaming /Users/floswald/git/EJData/blogs/stataversion/Burchardi/3-replication-package/Output/Tables/DEMED_AppendixTableB8_index.tex\n[\"/Users/floswald/git/EJData/blogs/stataversion/Burchardi/3-replication-package/Output/Tables/DEMED_AppendixTableB8_dummy-v16.tex\", \"/Users/floswald/git/EJData/blogs/stataversion/Burchardi/3-replication-package/Output/Tables/DEMED_AppendixTableB8_index-v16.tex\"]\n[ Info: run with stata 18\n[ Info: STATA version 18, docker IMG tag 2024-04-30\nWARNING: The requested image's platform (linux/amd64) does not match the detected host platform (linux/arm64/v8) and no specific platform was requested\n[ Info: done ğŸ‘‹\n\n\nStep 3: Results\nThe code repository also contains a short latex script which will compile the tables outputted from each docker container into a simple table. We can compare the result for each table across both versions. We can see for 2 columns a noticeable difference, both in estimates as well as in standard errors. The numbers in equally colored shapes should be identical.\n\n\n\nResults for Table B8 Panel A\n\n\n\n\n\n\nResults for Table B8 Panel B"
  },
  {
    "objectID": "posts/20240505-stataversions/index.html#conclusion",
    "href": "posts/20240505-stataversions/index.html#conclusion",
    "title": "STATA Versioning",
    "section": "Conclusion",
    "text": "Conclusion\nThe authors of Borrowing Constraints and Demand for Remedial Education: Evidence from Tanzania (forthcoming EJ 2024) have provided an excellent replication package which is available here. They alerted our team to a discrepancy arising from the xporegress command across STATA versions 16 vs 18. This is despite their correct usage of the version 16 command, and despite the insistence on the fact that everything will just work in the initial quote."
  },
  {
    "objectID": "replicator-resources.html",
    "href": "replicator-resources.html",
    "title": "Replicator Resources",
    "section": "",
    "text": "This page contains tips and tricks for replicators."
  },
  {
    "objectID": "replicator-resources.html#hard-coded-numbers",
    "href": "replicator-resources.html#hard-coded-numbers",
    "title": "Replicator Resources",
    "section": "Hard Coded Numbers",
    "text": "Hard Coded Numbers\n\nWithout proper documentation of how they were obtained, hard coded numbers are not admissible in code that generates results like plots or tables.\nPlots are particularly critical here.\nA fairly quick part of your work should be a scan of all source code to identify hard coded numbers and make sure everything is proper with those.\nHere is an example which triggers our suspicion: The below code is used to make a bar chart. However, the heights of the bars are hard coded as numbers. If it is not obvious where the numbers come from, then this fact should be a prominent feature in your report.\n\n\n\nhard coded numbers in code for a plot (python)\n\n\n\n\nHow to find hard coded numbers?\nRegular expressions (Regex) are the perfect tool for this. I recommend opening the full replication package in VScode. Here is an example. You can download the example package as usual from our dropbox at EJ-2-submitted-replication-packages/Oswald-123456-R1.\n\nOpen Package in VScode\n\n\n\nopening full replication package in VScode\n\n\nNext, activate the search function, either by clicking or by typing Cmd+Shift+F:\n\n\n\nactivating search in entire project\n\n\nMake sure to turn on regex search by clicking the symbol .* in the right of the search text box. Now you can enter regex search terms. Here, Iâ€™m entering \\d for digits (i.e.Â numbers), and Iâ€™m saying {3,10} to instruct the search to look for sequences of numbers with length in between 3 and 10. That is, numbers ranging from 3 up to 10 digits. You can change that of course. Notice how the search returns immediately all occurences of such numbers in the project.\n\n\n\nusing regex search to look for numbers between 3 and 10 digits long. plots.jl seems to contain hard coded numbers as source code.\n\n\nFinally, look whether any of those numbers do appear in a code file. Here, the plots.jl seems to be suspicious. Double click on a particular search results opens the relevant source file. Gotcha!\n\n\n\nExample of hard coded numbers to generate a plot. Unless the origin and reproducibililty of those numbers is clearly documented in the readme and in the source code, this is not admissible."
  },
  {
    "objectID": "replicator-resources.html#missing-software-libraries-in-readme",
    "href": "replicator-resources.html#missing-software-libraries-in-readme",
    "title": "Replicator Resources",
    "section": "Missing Software Libraries in README",
    "text": "Missing Software Libraries in README\n\nIt is very common that authors forget to list all required software libraries, or do not list the version information that goes with those libraries.\nBest practice would be to use an empty system where no libraries are pre-installed. The nuvolos platform is helpful here, because this is the case there."
  },
  {
    "objectID": "replicator-resources.html#python",
    "href": "replicator-resources.html#python",
    "title": "Replicator Resources",
    "section": "python",
    "text": "python\n\n\n\n\n\n\nWhere to get python?\n\n\n\nFirst things first. How can you get python on your computer? I strongly recommend the conda distribution - please follow instructions to install. This is what is available on nuvolos (i.e.Â nothing to do for python on nuvolos, itâ€™s there.)\n\n\nNext, on to our case study. An author says:\n\nWe use python. You must install the networkx package from pip. The rest of the packages is standard.\n\nThis is an incomplete specification on various counts.\n\nWe must know which python version to use. There are many.\nWe cannot work with the rest of the packages is standard. There is no notion of standard in this setting.\nInstalling via pip for instance depends on which particular python version is installed, and how that particular version of networkx relates to those standard packages mentioned above.\n\nğŸ‘‰ It is highly likely that following those instructions, we end up with a vastly different set of package (and base python!) versions than what the authors used on their machine.\nğŸ‘‰ Not good, because this alone could lead to diverging results and/or errors.\n\n\n\n\n\n\nSolution: Virtual Environments\n\n\n\nEasiest with anaconda on nuvolos or your own machine, but base python also has a solution.\n\nconda solution\nbase python solution\n\nI recommend the conda route.\n\n\nLetâ€™s solve this particular case. We will create a virtual environment for ourselves, making some assumptions along the way. We can at least communicate with the authors on that assumed basis. Therefore, we open VScode and look at the notebook file (notice this is much quicker than opening a jupyterlab session). We note that in the first code box they import the required libraries. We want to have an environment containing those packages.\n\n\n\nOpening a jupyter notebook in VSCode to see package dependencies\n\n\nThere are two ways to create an environment: on the command line or by writing a .yml file.\n\nCreating a conda env on the command line\nThis is easy.\n\nOpen a terminal in VScode via the command palette (type shift-cmd-p or click cogwheel bottom left). In the command palette type create new terminal and hit enter.\nIn the terminal window create the new environment, maybe called with the authorâ€™s name, specifying all required versions, as well as an assumed python version:\n# creates new virtual env called `author-name`\n# notice that the nuvolos terminal runs conda by default and tells\n# you that your are in the (base) environment now:\n(base) 11:35:56 - nuvolos:/files$ conda create -n author-name python=3.11 matplotlib pandas numpy networkx seaborn scipy  \n\nChannels:\n - defaults\n - conda-forge\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: - \nhit y when asked whether to install packages:\nDownloading and Extracting Packages:\n\nPreparing transaction: done                                                                 \nVerifying transaction: done                                                       \nExecuting transaction: done\n#                                                          \n# To activate this environment, use\n#                              \n#     $ conda activate author-name                                                          \n#                                       \n# To deactivate an active environment, use\n#                                                                                        \n#     $ conda deactivate \nAfter itâ€™s done, we can activate that environment. Notice the prompt switching to the new env.\n(base) 11:40:14 - nuvolos:/files$ conda activate author-name                                                                                                       \n(author-name) 11:41:42 - nuvolos:/files$             \nFrom that point on, we are sure what versions are being used when we say import networkx, for example:\n(author-name) 11:41:42 - nuvolos:/files$ python --version      \nPython 3.11.9  # we *asked* for that version!\n(author-name) 11:42:20 - nuvolos:/files$ python\nPython 3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; import networkx\n&gt;&gt;&gt; print(networkx.__version__)\n3.3   # that is default version compatible with our env\n&gt;&gt;&gt; \nSo, we are now using python 3.11.9 and networkx 3.3.\nOftentimes, authors supply jupyter notebooks (as in the present case). We need a way to run those inside our environment. So, we also install a notebook runner, while we are in the activated env:\n# install Python kernel in new conda env\n(author-name) 11:42:20 - nuvolos:/files$ conda install ipykernel\n# configure new notebook kernel\n(author-name) 11:42:20 - nuvolos:/files$ ipython kernel install --user --name=author-kernel   \nNow we can select kernel in the notebook view, i.e.Â we will choose the python engine which goes together with this particular environment.\n\n\n\nSelecting a Kernel from a python environment\n\n\n\n\n\nchoose our created author-name environment\n\n\nClicking on the â–¶ï¸ button left of each cell, we can run the contained code. Here I added two code cells to print python and networkx package versions.\n\n\n\nexecuting code in notebook using our environment. Notice that python and networkx versions correspond to our specs above.\n\n\n\nThe preceding steps of starting a notebook - from the external drive /space_mounts is illustrated in this video:\n\n\nCreating a conda env via a .yml file\nWe could have equally well created a full recipe file, from which to build this environment. This may be useful to share with authors. You would save that as author-env.yml for instance:\nname: author-name\ndependencies:\n  - python=3.11\n  - matplotlib\n  - seaborn\n  - netwworkx\n  - pandas\n  - numpy\n  - scipy\n  - ipykernel\n  - pip\nThen, one can create the env via\nconda env create -f author-env.yml\n\n\n\nCreating a conda env from a supplie .yml file\nSome authors actually give us such a file! In this case, the same applies:\n(base) 11:49:15 - nuvolos:/files$ conda env create -f /files/Replication_package_Agostini_Bloise_Tancioni/DML_python/environment.yml\n\ndone\n#\n# To activate this environment, use\n#\n#     $ conda activate ectj_abt\n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate\n\n(base) 09:52:23 - nuvolos:/files/Replication_package$ conda activate ectj_abt\n(ectj_abt) 09:55:17 - nuvolos:/files/Replication_package$ python --version\nPython 3.9.7\n(ectj_abt) 09:55:31 - nuvolos:/files/Replication_package$ python Main.py\nConda environment ectj_abt already exists. Skipping creation.\nRunning the estimation for dml_JJ...\n\n\n\n\n\n\nEnforce Best Practice\n\n\n\nIf a python package does not contain a virtual environment, you must recommend the authors to add this in your report."
  },
  {
    "objectID": "replicator-resources.html#stata",
    "href": "replicator-resources.html#stata",
    "title": "Replicator Resources",
    "section": "stata",
    "text": "stata\nThere is an excellent guide for how to lock in add-on stata packages into a certain state. By default, there is no mechanism in stata which would version add-on packages (the user is responsible to install the correct version - which may be extremely difficult in practice because older versions may no longer be retrievable).\n\n\n\n\n\n\nStata Library Guide\n\n\n\nThe relevant guide is by Julian Reif and accessible here."
  },
  {
    "objectID": "replicator-resources.html#julia",
    "href": "replicator-resources.html#julia",
    "title": "Replicator Resources",
    "section": "julia",
    "text": "julia\nEnvironment creating is built-in with base julia in the package manager. In any given directory, type ] to enter Pkg mode. Here we create an environment at the current directory . and add two packages. The resulting files Project.toml and Manifest.toml encode the exact versions of all component packages (i.e.Â including dependencies of the packages we are asking for). Any user can use those 2 files to recreate the exact same software environment as the author.\n(@v1.10) pkg&gt; activate .\n  Activating new project at `~/replications/Oswald-123456/full-package/3-replication-package`\n\n(3-replication-package) pkg&gt; add GLM DataFrames\n   Resolving package versions...\n   Installed LogExpFunctions â”€ v0.3.28\n   Installed Distributions â”€â”€â”€ v0.25.109\n    Updating `~/replications/Oswald-123456/full-package/3-replication-package/Project.toml`\n  [a93c6f00] + DataFrames v1.6.1\n  [38e38edf] + GLM v1.9.0\n    Updating `~/replications/Oswald-123456/full-package/3-replication-package/Manifest.toml`\n\n\n\n\n\n\n\nNo julia without Project.toml!\n\n\n\nWe require at least a Project.toml for any julia project. We strongly recommend supplying also a Manifest.toml from the authors."
  },
  {
    "objectID": "replicator-resources.html#memory-consumption",
    "href": "replicator-resources.html#memory-consumption",
    "title": "Replicator Resources",
    "section": "Memory Consumption",
    "text": "Memory Consumption\n\nNuvolos (and any shared resource like a HPC system) will strictly enforce memory (RAM) limits.\nIf your app consumes more than what is available, the app will be killed. You will not get an error message in most cases, but your app will just freeze or shut down.\nYou can increase the size (CPU + RAM) by clicking on the cogwheel next to the apps start button in the â€œApplicationsâ€ view."
  },
  {
    "objectID": "replicator-resources.html#large-files-on-nuvolos",
    "href": "replicator-resources.html#large-files-on-nuvolos",
    "title": "Replicator Resources",
    "section": "large files on nuvolos",
    "text": "large files on nuvolos\nYou can try the web-based uploader which will take any URL directly:\n\nWhen copying the dropbox URL, remember to change â€˜dl=0â€™ to â€˜dl=1â€™ inside the URL. This forces the download. For example:\nhttps://www.dropbox.com/scl/fo/gumryf1zs8lwk5zq5udo7/ABrnRWk5w859IIib/Author-YYYYMMDD-R1?*dl=1*\nTo rename the file, open the terminal and write\nmv 'old_file_name' 'new_file_name'\nIf the file is very large, move it to the â€˜large file storageâ€™ that you can create in the â€˜Project Configurationâ€™ tab on Nuvolos.\n(base) nuvolos@nuvolos:/files$ ls\n'old_file_name' 'some_folder'\n(base) nuvolos@nuvolos:/files$ mv 'old_file_name' 'new_file_name.zip'\n(base) nuvolos@nuvolos:/files$ mv 'new_file_name.zip' /space_mounts/mount_name/\nFor very large files, however, this does not work well and you need to use the dropbox sync integration. This will map a specific folder in your dropbox onto your nuvolos instance at /dropbox"
  },
  {
    "objectID": "replicator-resources.html#the-grf-random-forests-package",
    "href": "replicator-resources.html#the-grf-random-forests-package",
    "title": "Replicator Resources",
    "section": "The grf Random Forests Package",
    "text": "The grf Random Forests Package\nThere is a well-documented problem with cross platform compatibility. Only a certain setting of the regression_forest command will reproduce results across different platforms. The setting concerns the arguments num.threads and seed. Please make sure those are set. Reference here and example issue here"
  },
  {
    "objectID": "replicator-resources.html#sharing-full-r-libraries-does-not-work-in-general",
    "href": "replicator-resources.html#sharing-full-r-libraries-does-not-work-in-general",
    "title": "Replicator Resources",
    "section": "Sharing Full R Libraries does not work in general",
    "text": "Sharing Full R Libraries does not work in general\n\nyou cannot just include your direct dependencies in an R package and hope that just works.\nBy the way, R package need to be installed via a specific process (install.packages); it is not possible to copy a package directly into the local library location. For instance, for me this is\n\n&gt; .libPaths()\n[1] \"/Users/floswald/Library/R/arm64/4.2/library\"                         \n[2] \"/Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\"\nIf an author provides me with a set of libraries by just copying them out of their libPaths() and into the package, so that we could use them, this will only work under certain conditions; The OS and underlying compiler infrastructure need to be identical, for example. Simply put, if the author used MacOS 13.4.1, this will not work an any windows machine. It will most likely not work on any other MacOS either.\n\nR package installation may use system libraries and tools in order to build the package for your system. Most packages are pre-built binaries which just download and plug in, but some are not. This is particularly true for older versions, for which binaries are no long available.\n\n\nyou will miss upstream dependencies. RcppEigen was not provided here.\n\n&gt; install.packages(\"HDLPrepro_1.12.tar.gz\", repos = NULL, type = \"source\")\nInstalling package into â€˜/usr/local/lib/R/site-libraryâ€™\n(as â€˜libâ€™ is unspecified)\nERROR: dependencies â€˜bigtimeâ€™, â€˜deslaâ€™, â€˜ggpubrâ€™, â€˜rrpackâ€™, â€˜tsDynâ€™, â€˜varsâ€™, â€˜RcppProgressâ€™, â€˜sitmoâ€™ are not available for package â€˜HDLPreproâ€™\n* removing â€˜/usr/local/lib/R/site-library/HDLPreproâ€™\nWarning in install.packages :\n  installation of package â€˜HDLPrepro_1.12.tar.gzâ€™ had non-zero exit status\n&gt; \n&gt; install.packages(\"Backup copies of other packages/bigtime_0.2.2.tar.gz\", repos = NULL, type = \"source\")\nInstalling package into â€˜/usr/local/lib/R/site-libraryâ€™\n(as â€˜libâ€™ is unspecified)\nERROR: dependencies â€˜corrplotâ€™, â€˜RcppEigenâ€™ are not available for package â€˜bigtimeâ€™\n* removing â€˜/usr/local/lib/R/site-library/bigtimeâ€™\nWarning in install.packages :\n  installation of package â€˜Backup copies of other packages/bigtime_0.2.2.tar.gzâ€™ had non-zero exit status\nIn general, R is difficult in this regard if we have complicated version environments. The most advertised solution is renv, but I have to say that even this fails often for reasons outside the R environment, for example, a certain C compiler or fortran compiler with certain support libraries being needed to build a specific version of an outdate R package. While renv is a great step ahead, it is not a silver bullet."
  },
  {
    "objectID": "replicator-resources.html#dealing-with-large-files",
    "href": "replicator-resources.html#dealing-with-large-files",
    "title": "Replicator Resources",
    "section": "Dealing with Large Files",
    "text": "Dealing with Large Files\nLarge (data) files are complicated. Not only do they consume a lot of disk space, the real problem comes from transferring them over the internet. There may be losses along the way which invalidate the file.\n\n\n\n\n\n\nCheck if files are Identical?\n\n\n\nSuppose you have a 6GB dataset and want to quickly check whether it is identical to the previous version you obtained. You donâ€™t want to check each row of that dataset. Instead, you could compute the md5sum, which is akin to counting bits in the file in a certain kind of way and summing them up. Itâ€™s like a digital fingerprint of a file. For example to verify that file_to_check.csv is identical you would do on your linux/Mac terminal\nmd5sum file_to_check.csv\nin both versions of the package, and verify that the result is the same. On your windows powershell you would do this\nCertUtil -hashfile file_to_check.csv MD5\n\n\n\nCompression of files\n\nThere are several compression technologies out there, indicated by various filename endings .zip, .tar, .gz, .7z etc.\n\n\nThere are many different facets to compression which sometimes cause problems.\n\nThe md5 hash of a zip file create on one machine is not necessarily identical to the md5 hash of the zip file created on another machine - despite both having the exact same content. This is because different systems use different algorithms to create the zip file.\nFor zip files larger than 4GB, the macOS default archiver utility often fails with cryptic errors.\na good solution is the p7zip utility. Install via brew install p7zip and used like this: 7za x large_package_to_unzip.zip dest_name\nWe can split a zip into several smaller parts: https://superuser.com/questions/336219/how-do-i-split-a-zip-file-into-multiple-segments. For example we had to do this on this package."
  },
  {
    "objectID": "faqs.html",
    "href": "faqs.html",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "The following lines provide answers to some frequently asked questions about different aspects of the reproducibility checks and our data and code availability policy. Click on each question to display the answer."
  },
  {
    "objectID": "faqs.html#scope-of-reproducibility-checks-at-ej",
    "href": "faqs.html#scope-of-reproducibility-checks-at-ej",
    "title": "Frequently Asked Questions",
    "section": "Scope of Reproducibility Checks at EJ",
    "text": "Scope of Reproducibility Checks at EJ\n\nWhat is the exact nature of the reproducibility checks carried out at the Economic Journal?\n\n\nAnswer\n\nThe purpose of the reproducibility checks carried out at the Economic Journal is to verify three aspects of the replication package: (i) it is complete, in the sense of producing each table, figure, and in-text number in the paper and its appendices, including those online; (ii) it is self-contained, in the sense of not requiring a subprogram or module not included in the package; and (iii) the data and code are adequately documented for other researchers to be able to use them to replicate the results in the paper. When the data are accessible (included in the package or, in case of exemptions, via temporary access by the reproducibility team), the checks ensure that the code exactly reproduces the results in the paper and its appendices. In the case of a data exemption, authors may provide simulated or synthetic data to check that the code runs and produces all output, but the exact results cannot be checked. Reproducibility checks (not replication checks) are conducted. This means that our checks do not screen for coding errors, discrepancies between what the paper claims the code does and what it actually does, econometric errors, or whether the empirical approach followed in the paper can be reproduced in other environments or other datasets.\n\nAre the reproducibility checks implemented on online appendices?\n\n\nAnswer\n\nYes, the replication package should produce each table, figure, and in-text number in the paper and its appendices, including those online. All these codes are checked for their ability to produce the results in the paper and appendices.\n\nWhy is the Economic Journal running reproducibility checks? Why not replication checks?\n\n\nAnswer\n\nWe firmly believe that reproducibility and replicability are the main pillars of science. The nature of replication checks requires time, effort, and resources that journals typically do not have: the publication process should be speedy for science to advance at the right pace. Our reproducibility checks provide a necessary first step: to ensure that authors publish all available data and the codes that generate the results they present in the papers we publish, and, importantly, to check that these codes and data run and produce the published results. The certification that we provide enhances transparency, since it assures that other researchers can reproduce the published research and test it against other datasets, assumptions, methods, etc. It also provides an additional service to the authors, as we often detect small errors that are better amended before publication than in an erratum afterwards."
  },
  {
    "objectID": "faqs.html#data-and-code-availability-policy-and-exemptions",
    "href": "faqs.html#data-and-code-availability-policy-and-exemptions",
    "title": "Frequently Asked Questions",
    "section": "Data and Code Availability Policy and Exemptions",
    "text": "Data and Code Availability Policy and Exemptions\n\nMy paper uses publicly available data. Is it enough to indicate how to get them or should I provide my datasets as part of the replication package?\n\n\nAnswer\n\nEven publicly available data should be included in the replication package to ensure they remain available in the future for anyone who wants to replicate your results. The only exception is when your exact extract is published in a \"trusted\" repository (see the following list for guidance) with a permanent DOI. This is important, because datasets are often updated (or removed) by the provider, and your version of the data may no longer be available to researchers in the future.\n\nMy paper uses publicly available data. Does it imply that I certainly have the right to re-publish my dataset along with the replication package? If not, how can I obtain permission to publish the data?\n\n\nAnswer\n\nEach provider offers a different policy regarding re-distribution of original and transformed datasets. Some providers, for example, allow re-distribution as long as your extract is deposited in a specific repository. You should make sure about the restrictions to publish your data before the first submission. You should also make sure to seek permission from the original owner of the data to publish them, and make sure to cite the original source accordingly.\n\nCan I request an exemption to publish my data?\n\n\nAnswer\n\nYes, you can request an exemption on the grounds that the data are restricted-access. The request should be made at the time of initial submission, in a cover letter addressed to the Editor. The Editor in charge of your submission will determine whether your request is justified before submitting the paper to referees. If the Editor decides against the exemption, the manuscript will not be sent to referees, and you will be requested to either accept the data and code availability policy or otherwise the paper will be rejected. Submission fees will not be returned in that case. When an exemption is needed for a dataset that is incorporated to the analysis during the editorial process, the exemption should be requested at the first iteration in which the new data are incorporated.\n\nCan I request an exemption that affects only a part of my data?\n\n\nAnswer\n\nYes, provided that the request is made at the time of initial submission.\n\nIf my main dataset is available to publish, but there is a small portion of my data that I am not allowed to share, should I request a data exemption?\n\n\nAnswer\n\nYes. If you do not require a data exemption at the time of your first submission, you will be required to publish all the data used in your paper.\n\nIf the only data I am not allowed to share is only used in the online appendix, should I request a data exemption?\n\n\nAnswer\n\nYes. The data to produce all results in the paper and appendices, including those online, should be shared unless an exemption is requested and granted at the time of first submission.\n\nIf the data I use are publicly available to everyone, but I do not have permission to re-publish it, should I request a data exemption?\n\n\nAnswer\n\nYes. Unless you are granted an exemption at the time of first submission, you will be required to publish in the replication package all data to produce all results in the paper and appendices, including those online.\n\nCan I request an exemption later than the first initial submission?\n\n\nAnswer\n\nIn general, no. Later exemptions can only be requested for new data that is incorporated into the analysis during the editorial process. If your data cannot be published and you did not request the exemption at the time of initial submission, your paper may be rejected for publication at Economic Journal.\n\nIf my data are free of charge and available to any researcher who requests it from the data provider, but I donâ€™t have the right to publish it with the replication package, should I request an exemption?\n\n\nAnswer\n\nYes. Whenever the data used for the analysis in the paper cannot be published with the replication package (or in an open-access \"trusted\" repository, see the following list for guidance on what constitutes a \"trusted\" repository) an exemption needs to be requested at the time of first submission. Only if the exact extract that was used in the study is published in the repository and it is readily available in the exact format that is called by the code, an exemption will not be requested.\n\nSome data providers only allow authors to distribute the data in specific open repositories (for example, the Panel Study of Income Dynamics only allows to distribute the data using the OpenICPSR Repository). Do I need to request an exemption in such cases?\n\n\nAnswer\n\nNo.Â Data archived in \"trusted\" open repositories (see the following list for guidance) is acceptable in the replication package provided what is published is the extract that was used in the study and it is readily available in the exact format that is called by your code. The Data Editor will evaluate the suitability of the repository.\n\nIf I published my data in an open repository, do I need to include it in the replication package?\n\n\nAnswer\n\nData archived in \"trusted\" open repositories (see the following list for guidance) is acceptable in the replication package provided what is published is the extract that was used in the study and it is readily available in the exact format that is called by the code. The Data Editor will evaluate the suitability of the repository and whether or not there is the need of publishing a copy with the package on the journalâ€™s repository.\n\nIf I publish my replication package on my website (or similar), do I need to submit a replication package?\n\n\nAnswer\n\nYes. Personal websites are not considered \"trusted\" open repositories, because there is no guarantee that the package will be systematically archived. See the following list for guidance on what constitutes a \"trusted\" repository.\n\nCan I request an exemption to publish my data because I collected these data and I want to keep exclusivity rights for future research?\n\n\nAnswer\n\nNo.Â The goal of our data and code availability policy is to ensure transparency and reproducibility of research, and this requires publishing the data you collected. If others can use your data, your research will gain visibility.\n\nCan I apply for data exemption if my data come from a commercial data provider (Datastream, Orbis, â€¦)?\n\n\nAnswer\n\nYes. Restricted access data is generally discouraged, but when the nature of your research largely relies on a specific dataset and cannot be conducted on an open alternative, those data are eligible for an exemption. However, you may be requested to provide a certification from the provider indicating that the data will be archived and made available to other users following the same procedure to request access to it.\n\nCan I request an exemption for the experimental data I collected?\n\n\nAnswer\n\nIn general, no. Data should be anonymized to ensure that subjects cannot be identified. Only when the nature of the study impedes such anonymization, the authors can request a data exemption, which will cover only the required minimum to ensure the anonymity of the experimental subjects.\n\nCan I request an exemption to publish my code?\n\n\nAnswer\n\nNo.\n\nCan I use any software, proprietary and open source?\n\n\nAnswer\n\nYes. Open source software is encouraged, but licensed software is allowed. If the authors use software which is rather uncommon and requires special licenses, we ask for their cooperation to find a solution (which might entail providing remote access to the authorsâ€™ machine to our replicators in extreme cases.).\n\nDo I need to publish packages and libraries that are used by my code but not part of the standard distribution of the software used?\n\n\nAnswer\n\nWhenever possible, yes. If these packages or libraries are available in open repositories (e.g.Â most Stata packages), a clear indication on how to download and use them is sufficient. If the libraries cannot be included in the packages and are not publicly available, the Data Editor will be in contact with the authors to coordinate on a feasible way to implement the checks."
  },
  {
    "objectID": "faqs.html#procedures-when-exemptions-are-granted",
    "href": "faqs.html#procedures-when-exemptions-are-granted",
    "title": "Frequently Asked Questions",
    "section": "Procedures when Exemptions Are Granted",
    "text": "Procedures when Exemptions Are Granted\n\nIf I was granted a data exemption, how should I proceed with the replication package?\n\n\nAnswer\n\nIf you were granted a data exemption, your paper would still need to go through reproducibility checks before final acceptance. In order to do so, you can either (i) grant temporary (distance or physical) access to the data to the reproducibility team for the sole purpose of the checks (the data will be destroyed or access terminated after the checks), or (ii) supply simulated or synthetic dataset(s) instead of the one(s) used in the analysis.\n\nWhat is the difference between simulated data and synthetic data?\n\n\nAnswer\n\nA simulated dataset is generated by a model (ideally, your model). A synthetic dataset is a scrambling or perturbation of the actual dataset to ensure anonymity.\n\nIs it better to provide temporary access to the restricted data or to provide a simulated/synthetic dataset?\n\n\nAnswer\n\nWhenever feasible, we strongly recommend providing temporary access to restricted data. There are numerous advantages of this approach: (i) it saves the effort of producing synthetic or simulated datasets; (ii) the certification provided by the journal is stronger in the sense that we certify that we have been able to reproduce the results published in the paper as opposed to only checking that the code is complete, runs, and produces output for all tables, figures, and in-text numbers published in the article and its printed and online appendices; (iii) we can detect if the results cannot be reproduced, which gives the authors a chance to fix any errors before publication.\n\nWhat is the procedure followed by the Economic Journal when I supply restricted datasets for the sole purpose of the reproducibility checks?\n\n\nAnswer\n\nThe reproducibility team will treat the data with the highest ethical standards, preventing any violations of confidentiality, and using them exclusively to run the reproducibility checks. The restricted datasets will be destroyed as soon as the checks are performed and, therefore, they will not be published.\n\nWhat shall I do if I am not allowed to provide temporary access to the confidential data, but the data provider can run the code to implement the reproducibility checks?\n\n\nAnswer\n\nEven if you cannot provide direct access to the reproducibility team, this option is preferred to the simulated/synthetic dataset alternative as long as the checks can be executed in a reasonable amount of time. In this case, you need to supply the replication package to the journal and the contact of the data provider. The reproducibility team will send the code to the provider and the provider will send the output back to the team, who will check the results.\n\nWhat can I do if I am not allowed to provide temporary access to the confidential data, but a certification agency (e.g.Â cascad) can run the code in the original data source?\n\n\nAnswer\n\nThis option is still generally preferred to the simulated/synthetic dataset alternative. However, you should seek approval by the Data Editor before making any commitments with the certification agency. The Economic Journal, however, will NOT be able to cover the cost of certification.\n\nIf my restricted-access data provider has a public use testing sample (smaller sample, or perturbed dataset), can I provide this sample instead of a simulated/ synthetic dataset?\n\n\nAnswer\n\nIf this option is available, it is generally preferred to the simulated/synthetic dataset (but less preferred to providing temporary access to the original data) as long as the testing sample can be published with your package. Otherwise, a simulated/synthetic dataset that can be published with the package is preferred.\n\nWhat is the procedure followed by the Economic Journal if I supply simulated/synthetic datasets?\n\n\nAnswer\n\nThe simulated/synthetic dataset will be published with the replication package. Even if these are not the real data, their structure, which by design will largely mimic the actual dataset, will give readers a better sense of your data. Please make sure the manipulations used to produce the synthetic/simulated datasets are described in the ReadMe file.\n\nWhy am I requested to supply a simulated/synthetic data?\n\n\nAnswer\n\nOur view is that, when reproducibility checks cannot be performed on real data, there is still an advantage of running them on such simulated/synthetic datasets: they are still useful to make sure the code is complete and self-contained, and that it runs without errors.\n\nMy article estimates a non-linear model. The algorithm does not converge with randomly generated data. What shall I do?\n\n\nAnswer\n\nIn this case, we strongly recommend simulating data using your model as data generating process. If that is not feasible, please contact the Data Editor explaining in detail why this is the case. The Data Editor will either assist you in the process, and, eventually, s/he will make a proposal to your original Editor about how to handle the situation.\n\nHow do I decide whether to produce a simulated or a synthetic dataset?\n\n\nAnswer\n\nIn order to generate a dataset that mimics the same characteristics as the original one, the synthetic option may be easier. There are many open source routines that do it for you. However, there are also two main disadvantages: (i) you need to make sure that your scrambling/perturbation algorithm ensures correct anonymization of the data; and (ii) non-linear estimation routines may not converge on synthetic data, whereas they are more likely to converge in an artificial dataset generated by the model that you are estimating.\n\nHow should I produce a synthetic dataset?\n\n\nAnswer\n\nThere are multiple ways to generate it. You can find some useful links with helpful resources, mostly in R, here, here, here, and here"
  },
  {
    "objectID": "faqs.html#implementation-of-the-reproducibility-checks",
    "href": "faqs.html#implementation-of-the-reproducibility-checks",
    "title": "Frequently Asked Questions",
    "section": "Implementation of the Reproducibility Checks",
    "text": "Implementation of the Reproducibility Checks\n\nHow long do the reproducibility checks take?\n\n\nAnswer\n\nWe usually provide the outcome of our reproducibility checks in less than two weeks. If the package is not complete or the code does not run, more than one iteration may be required, in which case the processing time might be increased. Articles that require a relatively long running time may take longer. The processing time also depends on how responsive the authors are to our requests.\n\nHow do the reproducibility checks work?\n\n\nAnswer\n\nThe reproducibility checks are handled by our Data Editor and our reproducibility team: a team of advanced Ph.D.Â students that have been hired to carry out the checks under the supervision of the Data Editor. Once an article is conditionally accepted for publication at the Economic Journal, the authors are requested to submit the replication package along with other production files. Upon submission, the Data Editor assigns the package to one or several members of the reproducibility team. The reproducibility team provides the Data Editor with a report summarizing the outcome of the checks. After reviewing it, the Data Editor contacts the authors informing them about the outcome of the replication checks, and eventually requests them to amend the package if needed. Once the replication checks are completed, the article is transferred back to the original Editor, who is in charge of final acceptance. If results in the paper need to be modified as a result of the checks, the original Editor in charge will be responsible for approving these changes before acceptance. If these changes imply a modification of the message of the paper, the original Editor can decide to reject the paper. Final acceptance is conditional on full reproducibility.\n\nWill the Economic Journal run my code?\n\n\nAnswer\n\nYes. Upon submission, the Data Editor assigns the package to one or several members of the reproducibility team, who will run your code and check the output generated. The reproducibility team provides the Data Editor with a report summarizing the outcome of the checks. In some instances, the code is too demanding to be run in a reasonable amount of time. In such cases, the Data Editor will be in contact with you with a recommendation for supplying a simplified version of the code that allows testing the essential parts of the code.\n\nWhat happens if my code is highly demanding computationally?\n\n\nAnswer\n\nIf the code is too demanding to be run in a reasonable amount of time, the Data Editor will be in contact with you with a recommendation for supplying a simplified version of the code that allows testing the essential parts of the code. For example, this can entail a reduced number of replications of a simulation exercise, the code that solves a structural model for a given set of parameters, a simplified function to test an optimization routine, etc. Such a simplified \"testing\" version will be published along with the original code in your replication package. This is so because we believe that these testing versions are extremely useful for other researchers that want to understand and use your code for replication or their related research, enhancing transparency and increasing the visibility of your research.\n\nWhat happens if the results fail to reproduce?\n\n\nAnswer\n\nIf the data and code that you provided fail to replicate the results in the paper, the Data Editor will be in contact with you to identify the source of the discrepancy. Once the reproducibility checks are completed, if the discrepancy implies a change in the results presented in the paper or online appendices, even if minor, the Data Editor will notify it to the original Editor in charge. The Editor in charge will be responsible for approving these changes before acceptance. If these changes imply a modification of the message of the paper, the original Editor can decide to reject the paper. Final acceptance is conditional on full reproducibility.\n\nWhat happens if the replication package I provided is not complete?\n\n\nAnswer\n\nThe Data Editor will be in contact with you indicating the amendments and additions that need to be done to the replication package to pass the reproducibility checks. Once amended, the revised package will go through the checks again.\n\nWhat happens if the file I provided is not complete?\n\n\nAnswer\n\nThe Data Editor will be in contact with you indicating the amendments and additions that need to be done to the replication package to pass the reproducibility checks. Once amended, the revised package will go through the checks again.\n\nWhy do I need to resubmit the entire package (instead of only the revised part of it) when I incorporate the feedback received from the Data Editor and the reproducibility team?\n\n\nAnswer\n\nWe need you to submit the entire package again because updating the replication package ourselves increases the potential risk that the files you intend to submit for possible publication may be mishandled."
  },
  {
    "objectID": "faqs.html#content-of-the-replication-package",
    "href": "faqs.html#content-of-the-replication-package",
    "title": "Frequently Asked Questions",
    "section": "Content of the Replication Package",
    "text": "Content of the Replication Package\n\nWhat should be included in the replication package? Please see here.\nHow do I provide physical access to the replication team to my restricted-access data when I have been granted a data exemption?\n\n\nAnswer\n\nWhenever possible, the easiest way is to provide a physical copy of your data by including it in a separate folder labeled \"4 Confidential data not for publication\" outside of the replication package. All replicators and the Data Editor have signed confidentiality agreements that prevent them to use the data for any other purpose than the reproducibility checks. When that option is not feasible, we recommend you to contact our Data Editor to arrange the best way to provide access to the reproducibility team.\n\nWhy do I need to submit a signed checklist?\n\n\nAnswer\n\nTo ensure that you do not forget all elements of the replication package. This avoids repeated iterations and speeds up the process.\n\nShould I respect the folder structure dictated by the checklist, or is it only for orientation?\n\n\nAnswer\n\nYes, you should and it is very important to do so. When submitted to production, your package is handled by different people at the Economic Journal and at the publisher, not all of them familiarized with data and code. Respecting the folder structure ensures that your package is published correctly.\n\nWhat information should be included in the ReadMe file? Please see here.\nShould I submit the raw data files and the code that generates my final dataset from them?\n\n\nAnswer\n\nYes, this is requested by our Data and Code Availability Policy.\n\nWhy do I need to supply all text documents (ReadMe, IRB, etc.) in PDF format?\n\n\nAnswer\n\nThe PDF format is portable, which means that it can be transferred without having to worry about dependencies, fonts, etc. This ensures readability across platforms and users.\n\nWhy do I need to include a copy of all datasets in non-proprietary format (ASCII, csv, etc.)?\n\n\nAnswer\n\nSome users of your replication package may be not have access to the specific proprietary software that you used for your study. This ensures that they can have access to your data without problems. It also minimizes compatibility issues (e.g., old versions of Stata cannot open files saved by newer versions)."
  },
  {
    "objectID": "faqs.html#data-citations",
    "href": "faqs.html#data-citations",
    "title": "Frequently Asked Questions",
    "section": "Data Citations",
    "text": "Data Citations\n\nWhat data should I cite?\n\n\nAnswer\n\nAll datasets used in the paper (with no exceptions) should be cited both in the paper and in a dedicated section of the ReadMe file.\n\nIf I mention my datasets in the Online Appendix or in the ReadMe file, should I cite them?\n\n\nAnswer\n\nYes, all datasets used in the paper (with no exceptions) should be listed in the references section of the paper in the same way that we cite other papers, and a copy of these citations should appear in a dedicated section of the ReadMe file.\n\nHow should I cite my data?\n\n\nAnswer\n\nYou should cite all datasets used in the paper (with no exceptions) in the references section of the paper in the same way that we cite other papers, and a copy of these citations should appear in a dedicated section of the ReadMe file. You can find some examples in page 7 of this document. More specific guidance on data citations is available here.\n\nWhy should I cite my data?\n\n\nAnswer\n\nData citations are as fundamental as citations to other papers, if not more. Giving proper credit to data providers is in line with all scientific ethical standards. Moreover, giving proper credit to data providers ensures that they can keep receiving external funding to make their datasets publicly available for research."
  },
  {
    "objectID": "faqs.html#reproducibility-certification-publication-of-the-replication-package-and-copyright-issues",
    "href": "faqs.html#reproducibility-certification-publication-of-the-replication-package-and-copyright-issues",
    "title": "Frequently Asked Questions",
    "section": "Reproducibility Certification, Publication of the Replication Package and Copyright Issues",
    "text": "Reproducibility Certification, Publication of the Replication Package and Copyright Issues\n\nWhat kind of certification do we provide for papers that were checked for reproducibility?\n\n\nAnswer\n\nThe empirical/simulation/experimental papers that we checked include the following statement: \"The data and codes for this paper are available at [â€¦]. They were checked for their ability to reproduce the results presented in the paper.\" This statement is adjusted accordingly when data exemptions are granted (acknowledging either that the authors provided temporary access to the confidential data or that the checks were implemented on simulated/synthetic data provided by the authors). In particular, we either certify \"The authors were granted an exemption to publish their data because access to the data is restricted. However, the authors provided a simulated or synthetic dataset that allowed the Journal to run their codes. The synthetic/simulated data and codes are available at [â€¦]. They were checked for their ability to generate all tables and figures in the paper, however, the synthetic/simulated data are not designed to reproduce the same results.\" or \"The authors were granted an exemption to publish their data because access to the data is restricted. However, the authors provided the Journal with temporary access to the data, which allowed the Journal to run their codes. The codes are available at [â€¦]. The data and codes were checked for their ability to reproduce the results presented in the paper.\", depending on the case that is applicable. These statements are combined accordingly when more than one situation applies. The statements are also also adjusted when the nature of the algorithms is highly demanding, and a partial/simplified version of the code has been used for the reproducibility checks: we add the sentence \"Given the highly demanding nature of the algorithms, the replication checks were run on a simplified version of the code, which is also available at [â€¦]\" to the applicable statement.\n\nWhere will the replication package be published?\n\n\nAnswer\n\nAfter all reproducibility checks are completed, you will be requested by the Editorial Office to publish your checked package at the Economic Journalâ€™s community of Zenodo. Zenodo will assing your package a Digital Object Identifier (DOI), which then will be linked with your publication.\n\nDo I keep the copyright of my package?\n\n\nAnswer\n\nYes, one of the main advantages of you publishing the package at the Economic Journalâ€™s community at Zenodo is that you are the sole responsible and copyright owner of the specific publication. Therefore, it is important that you ensure that you have permission to publish your data before the time of first submission and request an exemption then if you donâ€™t.\n\nWhy are packages published at the Economic Journalâ€™s community at Zenodo instead of with the article on the Journalâ€™s website?\n\n\nAnswer\n\nThere are many advantages from publishing the package at the Economic Journalâ€™s community at Zenodo. Some of them are: (i) the author retains the copyright on the replication package, (ii) by having a specific DOI, it increases the visibility of all packages and, in turn, it increases the visibility of your article, and (iii) it makes it easier to cite.\n\nCan I post my replication material on other sites?\n\n\nAnswer\n\nYes, as long as one copy is published at the Economic Journalâ€™s community at Zenodo. The only exception is when your replication package is published in a \"trusted\" repository (see the following list for guidance) with a permanent DOI. In that case, your DOI can be used to link your article with your package, and the Data Editor can wave the requirement to publish the package at the Economic Journalâ€™s community at Zenodo. However, publishing your package at the Economic Journalâ€™s community at Zenodo is recommended, because it increases the visibility of your package.\n\nAll data is publicly available. Do I still need to get permission from the website owner to post data on Economic Journalâ€™s publisher website?\n\n\nAnswer\n\nEach provider offers a different policy regarding re-distribution of original and transformed datasets. Some providers, for example, allow re-distribution as long as your extract is deposited in a specific repository. You should make sure about the restrictions to publish your data before the first submission. You should also make sure to seek permission from the original owner of the data to publish them, and make sure to cite the original source accordingly. You will be the responsible of copyright infringements for what you publish with the replication package at the Economic Journalâ€™s community at Zenodo.\n\nCan I retrospectively include a replication package as supplementary online material to my Economic Journal article?\n\n\nAnswer\n\nYes. Please address your request to the Editorial Office at ej@res.org.uk"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "JPE Data Editor Website",
    "section": "",
    "text": "Work in Progress\nThis website provides all the relevant information regarding the Data and Code Availability Policy and pre-acceptance reproducibility checks implemented at the Journal of Political Economy.  \nFind more about our Data Editor. Data Editor"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog",
    "section": "",
    "text": "STATA Versioning\n\n\n\nSTATA\n\n\nversions\n\n\npackages\n\n\n\nChallenges when reproducing results with different versions of STATA\n\n\n\nFlorian Oswald\n\n\nApr 28, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "de.html",
    "href": "de.html",
    "title": "The JPE Data Editor",
    "section": "",
    "text": "The Data Editor of the JPE is Florian Oswald."
  }
]