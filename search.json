[
  {
    "objectID": "de.html",
    "href": "de.html",
    "title": "The JPE Data Editor",
    "section": "",
    "text": "Starting with July 1st 2025, the Data Editor of the JPE is Florian Oswald.",
    "crumbs": [
      "Data Editor"
    ]
  },
  {
    "objectID": "privacy.html",
    "href": "privacy.html",
    "title": "JPE Data Editor Website Privacy Policy",
    "section": "",
    "text": "This website sets cookies in order to track website traffic. We anonymize user IPs."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Journal of Political Economy  Data Editor Website",
    "section": "",
    "text": "This website provides relevant information regarding the Data and Code Availability Policy and pre-acceptance reproducibility checks implemented at the JPE.\n\n\nSchematic overview of the process:\n\n\n\n\n\nflowchart TD\n  X(Paper&lt;br&gt;conditionally accepted) --&gt; A\n  A(Author fills out &lt;br&gt; Data Availability Form) --&gt; B(Data Editor&lt;br&gt;sends &lt;i&gt;private&lt;/i&gt;&lt;br&gt;upload link)\n  B --&gt; C{Checks pass}\n  C --&gt; D[Yes: author uploads&lt;br&gt;to dataverse]\n  C --&gt; E[No: package goes&lt;br&gt;back to authors]\n  E --&gt; B\n\n\n Reproducibility Process. Notice that confidential data can be shared with the Data Editor for the purpose of checks, while it will be excluded from the published package on dataverse. \n\n\n\n\n\n\nPlease consider the following steps:\n 1. Read the JPE Policy   2. Before Submitting Your Package   3. Preparing the package   4. Best Practices   5. Frequently Asked Questions",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "package.html",
    "href": "package.html",
    "title": "Prepare and Submit your Replication Package",
    "section": "",
    "text": "Your package should be submitted as a single zip file. While we do not enforce any particular structure for the contents of this archive, we ask you to observe a few simple rules for operational reasons:\n\nAt the root of your package, there must be a README file in suitable format (.txt, .md or .pdf). We do not accept supplementary README files in other locations of the package - There should be a unique point for all required documentation.\nYou should clearly separate input, output and code in your package.\nIf your package depends on confidential data which you can share only on a temporary basis with the Data Editor, clearly separate this from the public data in your package in order to avoid mistaken publication of such data. We recommend to call this folder confidential-data-not-for-publication.\nIf the content of your package is larger than 10GB, zip compression becomes unstable. Please reach out to the Data Editor to agree on a way of splitting the content across multiple compressed files. In general, we aim for the smallest possible number of zip files below a 10GB threshold.\n\n\n\nHere are three examples for potential package structures. This is what we see after we unzip your package.\n\n\nExample 1 ✅\n.\n├── README.md\n├── code\n│   ├── R\n│   │   ├── 0-install.R\n│   │   ├── 1-main.R\n│   │   ├── 2-figure2.R\n│   │   └── 3-table2.R\n│   ├── stata\n│   │   ├── 1-main.do\n│   │   ├── 2-read_raw.do\n│   │   ├── 3-figure1.do\n│   │   ├── 4-figure2.do\n│   │   └── 5-table1.do\n│   └── tex\n│       ├── appendix.tex\n│       └── main.tex\n├── data\n│   ├── processed\n│   └── raw\n└── output\n    ├── plots\n    └── tables\n\nExample 2 ✅\n.\n├── README.pdf\n├── code\n│   ├── R\n│   └── fortran\n├── data\n│   ├── processed\n│   └── raw\n├── confidential-data-not-for-publication\n│   ├── processed\n│   └── raw\n└── output\nconfidential-data-not-for-publication is for Data Editor only.\n\nExample 3 ❌\n.\n├── README.docx\n├── 20211107ext_2v1.do\n├── 20220120ext_2v1.do\n├── 20221101wave1.dta\n├── matlab_fortran\n│   ├── graphs\n│   ├── sensitivity1\n│   │   ├── data.xlsx\n│   │   ├── good_version.do\n│   │   └── script.m\n│   └── sensitivity2\n│       ├── models.f90\n│       ├── models.mod\n│       └── nrtype.f90\n├── readme.do\n├── scatter1.eps\n├── scatter1_1.pdf\n├── scatter1_2.pdf\n├── ts.eps\n├── wave1.dta\n├── wave2.dta\n├── wave2regs.dta\n└── wave2regs2.dta\nThe Data Editor would ask you to improve the structure of this package: First, the readme is in the wrong format, second, input, output and code are mixed.\n\n\nKeep in mind that you can only include folder confidential-data-not-for-publication, if you have previously applied for exemption to the Data and Code Policy. There are relevant FAQs here, here, and here.",
    "crumbs": [
      "Preparing the Package"
    ]
  },
  {
    "objectID": "package.html#sec-structure",
    "href": "package.html#sec-structure",
    "title": "Prepare and Submit your Replication Package",
    "section": "",
    "text": "Your package should be submitted as a single zip file. While we do not enforce any particular structure for the contents of this archive, we ask you to observe a few simple rules for operational reasons:\n\nAt the root of your package, there must be a README file in suitable format (.txt, .md or .pdf). We do not accept supplementary README files in other locations of the package - There should be a unique point for all required documentation.\nYou should clearly separate input, output and code in your package.\nIf your package depends on confidential data which you can share only on a temporary basis with the Data Editor, clearly separate this from the public data in your package in order to avoid mistaken publication of such data. We recommend to call this folder confidential-data-not-for-publication.\nIf the content of your package is larger than 10GB, zip compression becomes unstable. Please reach out to the Data Editor to agree on a way of splitting the content across multiple compressed files. In general, we aim for the smallest possible number of zip files below a 10GB threshold.\n\n\n\nHere are three examples for potential package structures. This is what we see after we unzip your package.\n\n\nExample 1 ✅\n.\n├── README.md\n├── code\n│   ├── R\n│   │   ├── 0-install.R\n│   │   ├── 1-main.R\n│   │   ├── 2-figure2.R\n│   │   └── 3-table2.R\n│   ├── stata\n│   │   ├── 1-main.do\n│   │   ├── 2-read_raw.do\n│   │   ├── 3-figure1.do\n│   │   ├── 4-figure2.do\n│   │   └── 5-table1.do\n│   └── tex\n│       ├── appendix.tex\n│       └── main.tex\n├── data\n│   ├── processed\n│   └── raw\n└── output\n    ├── plots\n    └── tables\n\nExample 2 ✅\n.\n├── README.pdf\n├── code\n│   ├── R\n│   └── fortran\n├── data\n│   ├── processed\n│   └── raw\n├── confidential-data-not-for-publication\n│   ├── processed\n│   └── raw\n└── output\nconfidential-data-not-for-publication is for Data Editor only.\n\nExample 3 ❌\n.\n├── README.docx\n├── 20211107ext_2v1.do\n├── 20220120ext_2v1.do\n├── 20221101wave1.dta\n├── matlab_fortran\n│   ├── graphs\n│   ├── sensitivity1\n│   │   ├── data.xlsx\n│   │   ├── good_version.do\n│   │   └── script.m\n│   └── sensitivity2\n│       ├── models.f90\n│       ├── models.mod\n│       └── nrtype.f90\n├── readme.do\n├── scatter1.eps\n├── scatter1_1.pdf\n├── scatter1_2.pdf\n├── ts.eps\n├── wave1.dta\n├── wave2.dta\n├── wave2regs.dta\n└── wave2regs2.dta\nThe Data Editor would ask you to improve the structure of this package: First, the readme is in the wrong format, second, input, output and code are mixed.\n\n\nKeep in mind that you can only include folder confidential-data-not-for-publication, if you have previously applied for exemption to the Data and Code Policy. There are relevant FAQs here, here, and here.",
    "crumbs": [
      "Preparing the Package"
    ]
  },
  {
    "objectID": "package.html#contents-of-replication-package",
    "href": "package.html#contents-of-replication-package",
    "title": "Prepare and Submit your Replication Package",
    "section": "2 Contents of Replication Package",
    "text": "2 Contents of Replication Package\nAs indicated in the journal’s Data and Code Availability Policy all packages should include the following material:\n\nA README file in PDF format (README.pdf). We strongly recommend using this template. You may find in this web app a convenient tool to create your README file. The minimally required content of the readme is specified here. A comprehensive list is given below in Section 3.\nThe raw datasets used in the paper and online appendices, including a complete, transparent and precise documentation describing all variables. You can additionally provide the analysis data if this is helpful, but they are not required if the raw data are provided.\nIf you were granted a data exemption at the time of first submission (see here, here, and here for details), you should either provide the replication team with temporary access to the data for the sole purpose of performing the reproducibility checks, or you should submit a synthetic/simulated dataset that allows running the code and produce all outputs in the paper and appendices, even if the results do not match those in the paper. If you can provide temporary access but you cannot share the data in the 4-confidential-data-not-for-publication folder, please contact the Data Editor at jpe.dataeditor@gmail.com to arrange an alternative access method. The content of this folder will be destroyed after the reproducibility checks are completed. All replicators and the Data Editor have signed confidentiality agreements that protect your submission.\nBoth the data cleaning codes and the analysis codes that produce all reproducible outputs reported in the article, appendix, and online appendices (including figures, tables, and numbers reported in the text). If some results are produced without scripts (e.g. ArcGIS maps), the README file should include step-by-step very detailed instructions on how to produce that output. In case of simulation/Monte Carlo studies, the authors are requested to set a seed so that the exact numbers that are reported can be obtained.\nIf data are provided in proprietary format (e.g. Stata’s .dta), a copy of the data in non-proprietary format (e.g. ASCII, .csv).\n\nExperimental papers should additionally include the following PDF documents (if these files are part of the paper or of an appendix, copy them again in a separate document and include them in the replication package):\n\nA document outlining the design of the experiment.\nA copy of the instructions given to participants, in both the original language and an English translation.\nInformation on the selection and eligibility of participants.\nA PDF copy of the Institutional Review Board (IRB) approval of one of the authors’ institutions (IRB approval number, date, name of the institution) or an explicit mention that an exemption has been granted by the Editorial Board.",
    "crumbs": [
      "Preparing the Package"
    ]
  },
  {
    "objectID": "package.html#sec-package-readme",
    "href": "package.html#sec-package-readme",
    "title": "Prepare and Submit your Replication Package",
    "section": "3 The README File",
    "text": "3 The README File\nThe README file should provide enough instructions so that all users (level of an advanced PhD student and above) can reproduce all the results in the paper in a reasonable amount of time and without problems. We strongly recommend using this template.You may find in this web app a convenient tool to create your README file. The minimum required information includes:\n\nA verbal description of the content of the package (datasets, programs, folders, etc.)\nData Availability Statement: precise indications on how the data were obtained, including required registrations, memberships, application procedures, monetary cost, or other qualifications, and, if applicable, URL to download them (which is typically part of the data citation).\nThe following Statement about Rights:\n\nI certify that the author(s) of the manuscript have legitimate access to and permission to use the data used in this manuscript.\nI certify that the author(s) of the manuscript have documented permission to redistribute/publish the data contained within this replication package. Appropriate permission are documented in the LICENSE.txt file (if applicable).\n\nPrecise instructions on how to run the code.\nIndications on where each piece of output is saved or displayed.\nSoftware requirements, including the software version and operating system used by the authors.\nAll packages and libraries that need to be installed to run the code and a clear indication on how to obtain them.\nExpected running time (even if it is a few seconds). When relevant, include the hardware that the estimated time refers to.\nData citations: all datasets used in the paper (with no exceptions) should be listed in the references section of the paper in the same way that we cite other papers, and a copy of these citations should appear in a dedicated section of the ReadMe file. You can find some examples here",
    "crumbs": [
      "Preparing the Package"
    ]
  },
  {
    "objectID": "package.html#data-citations",
    "href": "package.html#data-citations",
    "title": "Prepare and Submit your Replication Package",
    "section": "4 Data Citations",
    "text": "4 Data Citations\nAll datasets used in the paper (with no exceptions) should be listed in the references section of the paper in the same way that we cite other papers, and a copy of these citations should appear in a dedicated section of the README file.\nIf the data used in the study is part of the replication package of another paper, both the paper and the replication package should be cited.\n\n\n\n\n\n\nData Citations Are Important!\n\n\n\nEven commonly used datasets should be cited (in fact, funding of public and private institutions that make datasets available, even the most widely used ones, crucially depends on data citations!).\n\n\nMore specific guidance, and examples, on data citations is available here.",
    "crumbs": [
      "Preparing the Package"
    ]
  },
  {
    "objectID": "package.html#submitting-your-package",
    "href": "package.html#submitting-your-package",
    "title": "Prepare and Submit your Replication Package",
    "section": "5 Submitting Your Package",
    "text": "5 Submitting Your Package\nYou will be invited to submit your package via an upload link by the Data Editor. This invitation will be generated after you have submitted the electronic form in your conditional acceptance email.\nA few days after you submitted the package (in most of the cases, within two weeks) you will be contacted by the Data Editor with the outcome of the reproducibility checks, regardless of whether the checks were successful or there are modifications to be made. Please add jpe.dataeditor@gmail.com and to your safe contacts to avoid that the Data Editor’s messages go to spam!\nIf you need to implement modifications of your package, you will be instructed to do so in the Data Editor’s response. You will iterate with the Data Editor until the reproducibility checks are satisfactorily concluded.",
    "crumbs": [
      "Preparing the Package"
    ]
  },
  {
    "objectID": "package.html#after-the-reproducibility-checks-are-completed-publish-your-package",
    "href": "package.html#after-the-reproducibility-checks-are-completed-publish-your-package",
    "title": "Prepare and Submit your Replication Package",
    "section": "6 After the reproducibility checks are completed: publish your package!",
    "text": "6 After the reproducibility checks are completed: publish your package!\nOnce the reproducibility checks are concluded, and upon invitation of the Data Editor, you will be requested to perform a final step: publish your replication package at the JPE Dataverse. To do so, you need to do the following:\n\nSign up here for a free account, if you don’t have one already.\nLog in and click on Add Data.\nYou must upload the exact same package which the Data Editor sign off on. This will be checked automatically\nHowever, do not include the content of the 4-confidential-data-not-for-publication folder!\nAfter verification of your deposit by the Data Editor, your package will be published on the JPE dataverse, and the process of reproducibility checks comes to an end.",
    "crumbs": [
      "Preparing the Package"
    ]
  },
  {
    "objectID": "before.html",
    "href": "before.html",
    "title": "Before you submit your Package",
    "section": "",
    "text": "Read here about our Data and Code Availability Policy and make sure you comply with all requirements before you submit the paper for the first time. Check the cases in which exemptions to the policy can be granted and the procedures to obtain them. If you don’t request the exemption at the time of first submission, you will not be able to do it later! Also, there may still be time to gain some insights from our best practice for reproducibility recommendations before you submit.",
    "crumbs": [
      "Before Submission"
    ]
  },
  {
    "objectID": "before.html#data-and-code-availability-policy",
    "href": "before.html#data-and-code-availability-policy",
    "title": "Before you submit your Package",
    "section": "Data and Code Availability Policy",
    "text": "Data and Code Availability Policy\n\n\n\n\n\n\nOfficial Policy at JPE\n\n\n\nThis is a reproduction of the official Data and Code Availability Policy of the JPE, which can be found here. In case of discrepancy, the official policy always prevails to the reproduction presented here.\n\n\nThe JPE requires authors of empirical, experimental or numerical papers to provide documentation of how their results were obtained in sufficient detail and accuracy to allow their results to be replicated. When you submit a paper for consideration, you will be asked to confirm that you are willing to comply with this policy. It is essential that you request a data exemption at the point of first submission if you face any restrictions that prevent you from publishing your data or, in general, from complying with any of the provisions of this policy. More details on this process are provided below.\n\n\n\n\n\n\nWhen Will my Paper be Accepted for Publication?\n\n\n\nYour paper will be accepted for final publication only after the results have been checked for reproducibility.\n\n\nOur mission is to conduct the reproducibility checks as fast as possible. Please read the information on this website carefully, so we can achieve this goal. Please, also note the following warning:\n\n\n\n\n\n\nWarning\n\n\n\nThe editorial board of the JPE reserves the right to refuse publication of papers whose authors do not comply with the requirements set out in detail below for each type of paper.\n\n\nOnce the paper is accepted for publication, the replication package will be posted on the journal’s repository at dataverse.edu and it will be linked with the paper. Submission on this online repository indicates that the authors license users to download, copy, and modify this material. Users of the material must acknowledge all authors as the original creators and cite both the replication package and the paper accordingly.\n\n\n\n\n\n\nInstructions for Replication Package\n\n\n\nPlease follow precise instructions on how to structure your replication package here.",
    "crumbs": [
      "Before Submission"
    ]
  },
  {
    "objectID": "before.html#sec-apply-exemption",
    "href": "before.html#sec-apply-exemption",
    "title": "Before you submit your Package",
    "section": "Apply to exemptions to the Data and Code Availability Policy",
    "text": "Apply to exemptions to the Data and Code Availability Policy\nIf you are not able to comply with some of the aspects of the Data and Code Availability Policy (e.g. because you are using restricted-access data or you cannot obtain permission to re-publish the data), you should request an exemption at the time of first submission of your paper. You can find a set of Frequently Asked Questions about the situations under which you can or cannot apply to an exemption to the data and code availability policy here.\nIf you want to request a Data Exemption, you should do so in a cover letter, explaining all relevant details about why you think an exemption is warranted.\nOnce the paper is submitted, the Managing Editor will analyze whether (i) there are enough grounds to grant the exemption and (ii) the exemption or the nature of the data limits the interest of the paper. Based on their assessment of these two points, they will make one of the following decisions: (a) move forward with the process, sending your paper to referees, (b) summarily reject your paper, or (c) contact you, asking to provide additional information, documentation, or any other requirement that they need to assess the suitability of the requested exemption. The exemptions are tacitly granted by choosing option (a).\nOnce your paper is conditionally accepted, you will be requested to supply your replication package according to the guidelines specified here on this website. If an exemption to the Data and Code Availability Policy was granted, you will be requested to either provide the Data Editor (and, by extension, the team of replicators) with temporary access to the data affected by the exemption for the sole purpose of implementing the reproducibility checks. Alternatively, when granting temporary access to the restricted data is not possible, you will be required to include in your package a synthetic or simulated dataset that allows users to run the code and check that it produces all outputs from the paper (and appendices), even if the results do not match those in the paper. This is all laid out in detail in the JPE Data and Code Policy. You can find a set of FAQs questions about how to proceed with the replication package when an exemption to the Data and Code Availability Policy has been granted here.",
    "crumbs": [
      "Before Submission"
    ]
  },
  {
    "objectID": "data-statements.html",
    "href": "data-statements.html",
    "title": "JPE Data Editor",
    "section": "",
    "text": "The replication package is deposited under DOI xyz.\n\n\n\n\n\n\n\n\nCode\nMeaning\nData Statement\n\n\n\n\nA\nAvailable\nData and code for this paper are available in the above deposit. They were checked by the Journal for their ability to reproduce the results presented in the paper.\n\n\nS\nSimulation\nThe authors were granted an exemption to publish their data because access is restricted. However, the authors provided a simulated or synthetic dataset that allowed the Journal to run their code. The synthetic/simulated data and code are available in the above deposit. They were checked for their ability to generate all tables and figures in the paper. However, the synthetic/simulated data are not designed to reproduce the same results.\n\n\nT\nTemporary\nThe authors were granted an exemption to publish their data because access is restricted. However, the authors provided the Journal with temporary access to the data, which allowed the Journal to run their code. Code and unrestricted data are available in the above deposit. Data and code were checked by the Journal for their ability to reproduce the results presented in the paper.\n\n\nP1\nPartial 1\nGiven the highly demanding nature of the algorithms, the reproducibility checks were run on a simplified version of the code, which is also available in the deposit. [which is to be added right after the end of any of the previous three statements].\n\n\nP2\nPartial 2\nGiven the highly demanding nature of the algorithms, the reproducibility checks were performed on a subset or results only. Those are clearly indicated in the accompanying README file of the replication package. [which is to be added right after the end of any of the previous three statements].\n\n\nA;T\nAvailable, Temporary\nData and code for this paper are available in the above deposit. They were checked by the Journal for their ability to reproduce the results presented in the paper. The authors were granted an exemption to publish parts of their data because access to these data is restricted. However, the authors provided the Journal with temporary access to the data, which enabled the Journal to check reproducibility of results. Code for all parts of the paper and unrestricted data are available in the above deposit.\n\n\nA;S\nAvailable, Simulation\nData and code for this paper are available in the above deposit. They were checked by the Journal for their ability to reproduce the results presented in the paper. The authors were granted an exemption to publish parts of their data because access to these data is restricted. However, the authors provided the Journal provided a simulated or synthetic dataset, which enabled the Journal to run the code. Code for all parts of the paper and unrestricted data are available in the above deposit. They were checked for their ability to generate all tables and figures in the paper, however the synthetic/simulated data are not designed to reproduce the same results.\n\n\nA;T;S\nAvailable, Temporary, Simulation\nData and code for this paper are available in the above deposit. They were checked by the Journal for their ability to reproduce the results presented in the paper. The authors were granted an exemption to publish parts of their data because access to these data is restricted. However, the authors provided the Journal with temporary access to the parts of the restricted data, which enabled the Journal to check reproducibility of results. Other parts of the data remained inaccessibel to the Journal, and the authors provided a simulated or synthetic dataset, which enabled the Journal to run the code. Code for all parts of the paper and unrestricted data are available in the above deposit. They were checked for their ability to generate all tables and figures in the paper, however the synthetic/simulated data are not designed to reproduce the same results."
  },
  {
    "objectID": "posts/20240505-stataversions/index.html",
    "href": "posts/20240505-stataversions/index.html",
    "title": "STATA Versioning",
    "section": "",
    "text": "This post is the first in a series where we want to analyse the behaviour of STATA in terms of cross-version reproducibility of results. In the current post, we will see inconsistent results for built-in STATA commands across versions, in a future post I plan to illlustrate problematic interactions with user-contributed code in the form of so-called .ado files (I will refer to those as packages). We will draw on real-world examples in the form of replication packages published together with academic papers in the Economic Journal. We will perform computational experiments by running identical code and data with different versions of STATA.\nThe starting point of this exploration is a blog post by the president of StataCorp from 2019 (with a similar message on the STATA website):\nWe will encounter below one example where we found behaviour which is incompatible with this statement. The aim of this post is not to discredit STATA in any way, but to provide hopefully useful advice on how to avoid distributing unreproducible code. In general, there is nothing which would make STATA better or worse suited to achieve reproducibility, and in this sense I humbly disagree with the above statement. Each language presents its own set of challenges, and being aware of those goes a long way. We reserve a comparison of computing languages in terms of being helpful to writing reproducible code for another occasion."
  },
  {
    "objectID": "posts/20240505-stataversions/index.html#stata-version-x-command",
    "href": "posts/20240505-stataversions/index.html#stata-version-x-command",
    "title": "STATA Versioning",
    "section": "Stata version x Command",
    "text": "Stata version x Command\nSTATA has a command version x which, if called, will mimick the STATA interpreter version x. The entry for help version gives a list of all known changes in behaviour if one sets version x, relative to the current version. The fact that this works is on the one hand nothing but remarkable - the code base of STATA must have changed considerably over the last few decades, surely countless bugs must have been fixed, etc, therefore ensuring that this works must require tremendous effort; on the other hand, it is obvious that version x does not replace the currently running STATA binary with the one of previous STATA version x, so any interactions of that binary with the current computing environment (OS, support libraries etc) could lead to unexpected behaviour. Indeed, we will document such behaviour below.\n\n\n\n\n\n\nData Editors do not care about backward compatibility\n\n\n\nIn general, Data Editors would not require that your code needs to be reproducible with all versions of STATA; quite on the contrary, we want a very specific description of the required environment. Another aim of this post is thus to clarify some (unexpected) effects of the version command, and to counter the belief that setting version will guarantee cross version reproducibility."
  },
  {
    "objectID": "posts/20240505-stataversions/index.html#case-study-xporegress-in-burchardi-et-al-ej-2024",
    "href": "posts/20240505-stataversions/index.html#case-study-xporegress-in-burchardi-et-al-ej-2024",
    "title": "STATA Versioning",
    "section": "Case Study: xporegress in Burchardi et al (EJ 2024)",
    "text": "Case Study: xporegress in Burchardi et al (EJ 2024)\n\nWe found different results for xporegress across STATA versions 16 and v 18 while checking the Burchardi et al (EJ 2024) paper. xporegress is a built-in STATA command.\nNotice we don’t know whether there is anything wrong in xporegress per se, or whether some other aspect of STATA code changed in a way which leads to different results across both verions. We are also agnostic about whether the authors were writing code in any way incompatible with STATA version 18, because:\nTo us, this is irrelevant, as we want to be able to rely on the promise embedded in version 16 solving all issues. The authors set version 16, as well as all required random seeds, in the correct fashion.\n\n\n\n\n\n\n\n🏆 Data Editor Award for Excellent Collaboration\n\n\n\nThe Burchardi et al package features high quality of code and exceptional collaboration on behalf of the authors. All results replicate exactly on STATA version 16, as indicated in their package readme. They were the first to point out the issue with xporegress to me. Thanks to them! 🤝\n\n\n\nStep 1: Safe Environment via docker\n\nWe want to minimize the risk that anything in our findings is driven by my local STATA installation, and its interaction with my OS. A good solution to this is a containerized environment, for example via docker.\nWe want to have 2 docker containers with version 16 and 18 respectively. We basically want to test the effect of the version 16 command on the stata 18 binary.\nThe dedicated repository of docker images provided by the AEA Data Editor Lars Vilhuber is going to be very helpful here. The prebuilt docker images for different stata versions are available here on dockerhub.\n\nWe can run STATA 16 and STATA 18 as if we had two separate machines inside an isolated environment (a container) on our own computer.\nNotice that there are no user contributed packages installed into those containers. Furthermore, Burchardi et al provide .ado files for add-on packages with their code. So, we have a clean slate.\n\n\n\n\nStep 2: Code to Run Experiment\nTo minimize further mistakes from manually handling code and results, I wrote some julia code which is available here. It downloads the Burchardi et al package from zenodo.org, unpacks it, modifies it slightly (so that it only produces the required appendix table B8 where the discrepancy arises), and then launches the respective STATA containers with the identical code and data; first version 16, where results correspond exactly to the paper, and then version 18, where they do not. The point being, given the promise contained in the version 16 command, results should correspond across versions.\nIf you follow instructions contained therein, you will see the following output in your terminal:\nfloswald@PTL11077 ~/g/E/b/stataversion (main)&gt; julia --project=. runblog.jl\n\n[ Info: downloading record Burchardi\n[ Info: content of /Users/floswald/git/EJData/blogs/stataversion/Burchardi/3-replication-package\n[\".DS_Store\", \"Code\", \"Data\", \"Materials\", \"Output\", \"README.pdf\"]\n[ Info: done downloading\n[ Info: run with stata 16\n[ Info: STATA version 16, docker IMG tag 2023-06-13\nWARNING: The requested image's platform (linux/amd64) does not match the detected host platform (linux/arm64/v8) and no specific platform was requested\n[ Info: renaming /Users/floswald/git/EJData/blogs/stataversion/Burchardi/3-replication-package/Output/Tables/DEMED_AppendixTableB8_dummy.tex\n[ Info: renaming /Users/floswald/git/EJData/blogs/stataversion/Burchardi/3-replication-package/Output/Tables/DEMED_AppendixTableB8_index.tex\n[\"/Users/floswald/git/EJData/blogs/stataversion/Burchardi/3-replication-package/Output/Tables/DEMED_AppendixTableB8_dummy-v16.tex\", \"/Users/floswald/git/EJData/blogs/stataversion/Burchardi/3-replication-package/Output/Tables/DEMED_AppendixTableB8_index-v16.tex\"]\n[ Info: run with stata 18\n[ Info: STATA version 18, docker IMG tag 2024-04-30\nWARNING: The requested image's platform (linux/amd64) does not match the detected host platform (linux/arm64/v8) and no specific platform was requested\n[ Info: done 👋\n\n\nStep 3: Results\nThe code repository also contains a short latex script which will compile the tables outputted from each docker container into a simple table. We can compare the result for each table across both versions. We can see for 2 columns a noticeable difference, both in estimates as well as in standard errors. The numbers in equally colored shapes should be identical.\n\n\n\nResults for Table B8 Panel A\n\n\n\n\n\n\nResults for Table B8 Panel B"
  },
  {
    "objectID": "posts/20240505-stataversions/index.html#conclusion",
    "href": "posts/20240505-stataversions/index.html#conclusion",
    "title": "STATA Versioning",
    "section": "Conclusion",
    "text": "Conclusion\nThe authors of Borrowing Constraints and Demand for Remedial Education: Evidence from Tanzania (forthcoming EJ 2024) have provided an excellent replication package which is available here. They alerted our team to a discrepancy arising from the xporegress command across STATA versions 16 vs 18. This is despite their correct usage of the version 16 command, and despite the insistence on the fact that everything will just work in the initial quote."
  },
  {
    "objectID": "faqs.html",
    "href": "faqs.html",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "The following lines provide answers to some frequently asked questions about different aspects of the reproducibility checks and our data and code availability policy. Click on each question to display the answer.",
    "crumbs": [
      "FAQs"
    ]
  },
  {
    "objectID": "faqs.html#scope-of-reproducibility-checks-at-jpe",
    "href": "faqs.html#scope-of-reproducibility-checks-at-jpe",
    "title": "Frequently Asked Questions",
    "section": "Scope of Reproducibility Checks at JPE",
    "text": "Scope of Reproducibility Checks at JPE\n\nWhat is the exact nature of the reproducibility checks carried out at the JPE?\n\n\nAnswer\n\nThe purpose of the reproducibility checks carried out at the JPE is to verify three aspects of the replication package: (i) it is complete, in the sense of producing each table, figure, and in-text number in the paper and its appendices, including those online; (ii) it is self-contained, in the sense of not requiring a subprogram or module not included in the package; and (iii) the data and code are adequately documented for other researchers to be able to use them to replicate the results in the paper. When the data are accessible (included in the package or, in case of exemptions, via temporary access by the reproducibility team), the checks ensure that the code exactly reproduces the results in the paper and its appendices. In the case of a data exemption, authors may provide simulated or synthetic data to check that the code runs and produces all output, but the exact results cannot be checked. Reproducibility checks (not replication checks) are conducted. This means that our checks do not screen for coding errors, discrepancies between what the paper claims the code does and what it actually does, econometric errors, or whether the empirical approach followed in the paper can be reproduced in other environments or other datasets.\n\nAre the reproducibility checks implemented on online appendices?\n\n\nAnswer\n\nYes, the replication package should produce each table, figure, and in-text number in the paper and its appendices, including those online. All these codes are checked for their ability to produce the results in the paper and appendices.\n\nWhy is the JPE running reproducibility checks? Why not replication checks?\n\n\nAnswer\n\nWe firmly believe that reproducibility and replicability are the main pillars of science. The nature of replication checks requires time, effort, and resources that journals typically do not have: the publication process should be speedy for science to advance at the right pace. Our reproducibility checks provide a necessary first step: to ensure that authors publish all available data and the codes that generate the results they present in the papers we publish, and, importantly, to check that these codes and data run and produce the published results. The certification that we provide enhances transparency, since it assures that other researchers can reproduce the published research and test it against other datasets, assumptions, methods, etc. It also provides an additional service to the authors, as we often detect small errors that are better amended before publication than in an erratum afterwards.",
    "crumbs": [
      "FAQs"
    ]
  },
  {
    "objectID": "faqs.html#data-and-code-availability-policy-and-exemptions",
    "href": "faqs.html#data-and-code-availability-policy-and-exemptions",
    "title": "Frequently Asked Questions",
    "section": "Data and Code Availability Policy and Exemptions",
    "text": "Data and Code Availability Policy and Exemptions\n\nMy paper uses publicly available data. Is it enough to indicate how to get them or should I provide my datasets as part of the replication package?\n\n\nAnswer\n\nEven publicly available data should be included in the replication package to ensure they remain available in the future for anyone who wants to replicate your results. The only exception is when your exact extract is published in a \"trusted\" repository (see the following list for guidance) with a permanent DOI. This is important, because datasets are often updated (or removed) by the provider, and your version of the data may no longer be available to researchers in the future.\n\nMy paper uses publicly available data. Does it imply that I certainly have the right to re-publish my dataset along with the replication package? If not, how can I obtain permission to publish the data?\n\n\nAnswer\n\nEach provider offers a different policy regarding re-distribution of original and transformed datasets. Some providers, for example, allow re-distribution as long as your extract is deposited in a specific repository. You should make sure about the restrictions to publish your data before the first submission. You should also make sure to seek permission from the original owner of the data to publish them, and make sure to cite the original source accordingly.\n\nCan I request an exemption to publish my data?\n\n\nAnswer\n\nYes, you can request an exemption on the grounds that the data are restricted-access. The request should be made at the time of initial submission, in a cover letter addressed to the Editor. The Editor in charge of your submission will determine whether your request is justified before submitting the paper to referees. If the Editor decides against the exemption, the manuscript will not be sent to referees, and you will be requested to either accept the data and code availability policy or otherwise the paper will be rJPEected. Submission fees will not be returned in that case. When an exemption is needed for a dataset that is incorporated to the analysis during the editorial process, the exemption should be requested at the first iteration in which the new data are incorporated.\n\nCan I request an exemption that affects only a part of my data?\n\n\nAnswer\n\nYes, provided that the request is made at the time of initial submission.\n\nIf my main dataset is available to publish, but there is a small portion of my data that I am not allowed to share, should I request a data exemption?\n\n\nAnswer\n\nYes. If you do not require a data exemption at the time of your first submission, you will be required to publish all the data used in your paper.\n\nIf the only data I am not allowed to share is only used in the online appendix, should I request a data exemption?\n\n\nAnswer\n\nYes. The data to produce all results in the paper and appendices, including those online, should be shared unless an exemption is requested and granted at the time of first submission.\n\nIf the data I use are publicly available to everyone, but I do not have permission to re-publish it, should I request a data exemption?\n\n\nAnswer\n\nYes. Unless you are granted an exemption at the time of first submission, you will be required to publish in the replication package all data to produce all results in the paper and appendices, including those online.\n\nCan I request an exemption later than the first initial submission?\n\n\nAnswer\n\nIn general, no. Later exemptions can only be requested for new data that is incorporated into the analysis during the editorial process. If your data cannot be published and you did not request the exemption at the time of initial submission, your paper may be rJPEected for publication at JPE.\n\nIf my data are free of charge and available to any researcher who requests it from the data provider, but I don’t have the right to publish it with the replication package, should I request an exemption?\n\n\nAnswer\n\nYes. Whenever the data used for the analysis in the paper cannot be published with the replication package (or in an open-access \"trusted\" repository, see the following list for guidance on what constitutes a \"trusted\" repository) an exemption needs to be requested at the time of first submission. Only if the exact extract that was used in the study is published in the repository and it is readily available in the exact format that is called by the code, an exemption will not be requested.\n\nSome data providers only allow authors to distribute the data in specific open repositories (for example, the Panel Study of Income Dynamics only allows to distribute the data using the OpenICPSR Repository). Do I need to request an exemption in such cases?\n\n\nAnswer\n\nNo. Data archived in \"trusted\" open repositories (see the following list for guidance) is acceptable in the replication package provided what is published is the extract that was used in the study and it is readily available in the exact format that is called by your code. The Data Editor will evaluate the suitability of the repository.\n\nIf I published my data in an open repository, do I need to include it in the replication package?\n\n\nAnswer\n\nData archived in \"trusted\" open repositories (see the following list for guidance) is acceptable in the replication package provided what is published is the extract that was used in the study and it is readily available in the exact format that is called by the code. The Data Editor will evaluate the suitability of the repository and whether or not there is the need of publishing a copy with the package on the journal’s repository.\n\nIf I publish my replication package on my website (or similar), do I need to submit a replication package?\n\n\nAnswer\n\nYes. Personal websites are not considered \"trusted\" open repositories, because there is no guarantee that the package will be systematically archived. See the following list for guidance on what constitutes a \"trusted\" repository.\n\nCan I request an exemption to publish my data because I collected these data and I want to keep exclusivity rights for future research?\n\n\nAnswer\n\nNo. The goal of our data and code availability policy is to ensure transparency and reproducibility of research, and this requires publishing the data you collected. If others can use your data, your research will gain visibility.\n\nCan I apply for data exemption if my data come from a commercial data provider (Datastream, Orbis, …)?\n\n\nAnswer\n\nYes. Restricted access data is generally discouraged, but when the nature of your research largely relies on a specific dataset and cannot be conducted on an open alternative, those data are eligible for an exemption. However, you may be requested to provide a certification from the provider indicating that the data will be archived and made available to other users following the same procedure to request access to it.\n\nCan I request an exemption for the experimental data I collected?\n\n\nAnswer\n\nIn general, no. Data should be anonymized to ensure that subjects cannot be identified. Only when the nature of the study impedes such anonymization, the authors can request a data exemption, which will cover only the required minimum to ensure the anonymity of the experimental subjects.\n\nCan I request an exemption to publish my code?\n\n\nAnswer\n\nNo.\n\nCan I use any software, proprietary and open source?\n\n\nAnswer\n\nYes. Open source software is encouraged, but licensed software is allowed. If the authors use software which is rather uncommon and requires special licenses, we ask for their cooperation to find a solution (which might entail providing remote access to the authors’ machine to our replicators in extreme cases.).\n\nDo I need to publish packages and libraries that are used by my code but not part of the standard distribution of the software used?\n\n\nAnswer\n\nWhenever possible, yes. If these packages or libraries are available in open repositories (e.g. most Stata packages), a clear indication on how to download and use them is sufficient. If the libraries cannot be included in the packages and are not publicly available, the Data Editor will be in contact with the authors to coordinate on a feasible way to implement the checks.",
    "crumbs": [
      "FAQs"
    ]
  },
  {
    "objectID": "faqs.html#procedures-when-exemptions-are-granted",
    "href": "faqs.html#procedures-when-exemptions-are-granted",
    "title": "Frequently Asked Questions",
    "section": "Procedures when Exemptions Are Granted",
    "text": "Procedures when Exemptions Are Granted\n\nIf I was granted a data exemption, how should I proceed with the replication package?\n\n\nAnswer\n\nIf you were granted a data exemption, your paper would still need to go through reproducibility checks before final acceptance. In order to do so, you can either (i) grant temporary (distance or physical) access to the data to the reproducibility team for the sole purpose of the checks (the data will be destroyed or access terminated after the checks), or (ii) supply simulated or synthetic dataset(s) instead of the one(s) used in the analysis.\n\nWhat is the difference between simulated data and synthetic data?\n\n\nAnswer\n\nA simulated dataset is generated by a model (ideally, your model). A synthetic dataset is a scrambling or perturbation of the actual dataset to ensure anonymity.\n\nIs it better to provide temporary access to the restricted data or to provide a simulated/synthetic dataset?\n\n\nAnswer\n\nWhenever feasible, we strongly recommend providing temporary access to restricted data. There are numerous advantages of this approach: (i) it saves the effort of producing synthetic or simulated datasets; (ii) the certification provided by the journal is stronger in the sense that we certify that we have been able to reproduce the results published in the paper as opposed to only checking that the code is complete, runs, and produces output for all tables, figures, and in-text numbers published in the article and its printed and online appendices; (iii) we can detect if the results cannot be reproduced, which gives the authors a chance to fix any errors before publication.\n\nWhat is the procedure followed by the JPE when I supply restricted datasets for the sole purpose of the reproducibility checks?\n\n\nAnswer\n\nThe reproducibility team will treat the data with the highest ethical standards, preventing any violations of confidentiality, and using them exclusively to run the reproducibility checks. The restricted datasets will be destroyed as soon as the checks are performed and, therefore, they will not be published.\n\nWhat shall I do if I am not allowed to provide temporary access to the confidential data, but the data provider can run the code to implement the reproducibility checks?\n\n\nAnswer\n\nEven if you cannot provide direct access to the reproducibility team, this option is preferred to the simulated/synthetic dataset alternative as long as the checks can be executed in a reasonable amount of time. In this case, you need to supply the replication package to the journal and the contact of the data provider. The reproducibility team will send the code to the provider and the provider will send the output back to the team, who will check the results.\n\nWhat can I do if I am not allowed to provide temporary access to the confidential data, but a certification agency (e.g. cascad) can run the code in the original data source?\n\n\nAnswer\n\nThis option is still generally preferred to the simulated/synthetic dataset alternative. However, you should seek approval by the Data Editor before making any commitments with the certification agency. The JPE, however, will NOT be able to cover the cost of certification.\n\nIf my restricted-access data provider has a public use testing sample (smaller sample, or perturbed dataset), can I provide this sample instead of a simulated/ synthetic dataset?\n\n\nAnswer\n\nIf this option is available, it is generally preferred to the simulated/synthetic dataset (but less preferred to providing temporary access to the original data) as long as the testing sample can be published with your package. Otherwise, a simulated/synthetic dataset that can be published with the package is preferred.\n\nWhat is the procedure followed by the JPE if I supply simulated/synthetic datasets?\n\n\nAnswer\n\nThe simulated/synthetic dataset will be published with the replication package. Even if these are not the real data, their structure, which by design will largely mimic the actual dataset, will give readers a better sense of your data. Please make sure the manipulations used to produce the synthetic/simulated datasets are described in the ReadMe file.\n\nWhy am I requested to supply a simulated/synthetic data?\n\n\nAnswer\n\nOur view is that, when reproducibility checks cannot be performed on real data, there is still an advantage of running them on such simulated/synthetic datasets: they are still useful to make sure the code is complete and self-contained, and that it runs without errors.\n\nMy article estimates a non-linear model. The algorithm does not converge with randomly generated data. What shall I do?\n\n\nAnswer\n\nIn this case, we strongly recommend simulating data using your model as data generating process. If that is not feasible, please contact the Data Editor explaining in detail why this is the case. The Data Editor will either assist you in the process, and, eventually, s/he will make a proposal to your original Editor about how to handle the situation.\n\nHow do I decide whether to produce a simulated or a synthetic dataset?\n\n\nAnswer\n\nIn order to generate a dataset that mimics the same characteristics as the original one, the synthetic option may be easier. There are many open source routines that do it for you. However, there are also two main disadvantages: (i) you need to make sure that your scrambling/perturbation algorithm ensures correct anonymization of the data; and (ii) non-linear estimation routines may not converge on synthetic data, whereas they are more likely to converge in an artificial dataset generated by the model that you are estimating.\n\nHow should I produce a synthetic dataset?\n\n\nAnswer\n\nThere are multiple ways to generate it. You can find some useful links with helpful resources, mostly in R, here, here, here, and here",
    "crumbs": [
      "FAQs"
    ]
  },
  {
    "objectID": "faqs.html#implementation-of-the-reproducibility-checks",
    "href": "faqs.html#implementation-of-the-reproducibility-checks",
    "title": "Frequently Asked Questions",
    "section": "Implementation of the Reproducibility Checks",
    "text": "Implementation of the Reproducibility Checks\n\nHow long do the reproducibility checks take?\n\n\nAnswer\n\nWe usually provide the outcome of our reproducibility checks in less than two weeks. If the package is not complete or the code does not run, more than one iteration may be required, in which case the processing time might be increased. Articles that require a relatively long running time may take longer. The processing time also depends on how responsive the authors are to our requests.\n\nHow do the reproducibility checks work?\n\n\nAnswer\n\nThe reproducibility checks are handled by our Data Editor and our reproducibility team: a team of advanced Ph.D. students that have been hired to carry out the checks under the supervision of the Data Editor. Once an article is conditionally accepted for publication at the JPE, the authors are requested to submit the replication package along with other production files. Upon submission, the Data Editor assigns the package to one or several members of the reproducibility team. The reproducibility team provides the Data Editor with a report summarizing the outcome of the checks. After reviewing it, the Data Editor contacts the authors informing them about the outcome of the replication checks, and eventually requests them to amend the package if needed. Once the replication checks are completed, the article is transferred back to the original Editor, who is in charge of final acceptance. If results in the paper need to be modified as a result of the checks, the original Editor in charge will be responsible for approving these changes before acceptance. If these changes imply a modification of the message of the paper, the original Editor can decide to rJPEect the paper. Final acceptance is conditional on full reproducibility.\n\nWill the JPE run my code?\n\n\nAnswer\n\nYes. Upon submission, the Data Editor assigns the package to one or several members of the reproducibility team, who will run your code and check the output generated. The reproducibility team provides the Data Editor with a report summarizing the outcome of the checks. In some instances, the code is too demanding to be run in a reasonable amount of time. In such cases, the Data Editor will be in contact with you with a recommendation for supplying a simplified version of the code that allows testing the essential parts of the code.\n\nWhat happens if my code is highly demanding computationally?\n\n\nAnswer\n\nIf the code is too demanding to be run in a reasonable amount of time, the Data Editor will be in contact with you with a recommendation for supplying a simplified version of the code that allows testing the essential parts of the code. For example, this can entail a reduced number of replications of a simulation exercise, the code that solves a structural model for a given set of parameters, a simplified function to test an optimization routine, etc. Such a simplified \"testing\" version will be published along with the original code in your replication package. This is so because we believe that these testing versions are extremely useful for other researchers that want to understand and use your code for replication or their related research, enhancing transparency and increasing the visibility of your research.\n\nWhat happens if the results fail to reproduce?\n\n\nAnswer\n\nIf the data and code that you provided fail to replicate the results in the paper, the Data Editor will be in contact with you to identify the source of the discrepancy. Once the reproducibility checks are completed, if the discrepancy implies a change in the results presented in the paper or online appendices, even if minor, the Data Editor will notify it to the original Editor in charge. The Editor in charge will be responsible for approving these changes before acceptance. If these changes imply a modification of the message of the paper, the original Editor can decide to rJPEect the paper. Final acceptance is conditional on full reproducibility.\n\nWhat happens if the replication package I provided is not complete?\n\n\nAnswer\n\nThe Data Editor will be in contact with you indicating the amendments and additions that need to be done to the replication package to pass the reproducibility checks. Once amended, the revised package will go through the checks again.\n\nWhat happens if the file I provided is not complete?\n\n\nAnswer\n\nThe Data Editor will be in contact with you indicating the amendments and additions that need to be done to the replication package to pass the reproducibility checks. Once amended, the revised package will go through the checks again.\n\nWhy do I need to resubmit the entire package (instead of only the revised part of it) when I incorporate the feedback received from the Data Editor and the reproducibility team?\n\n\nAnswer\n\nWe need you to submit the entire package again because updating the replication package ourselves increases the potential risk that the files you intend to submit for possible publication may be mishandled.",
    "crumbs": [
      "FAQs"
    ]
  },
  {
    "objectID": "faqs.html#content-of-the-replication-package",
    "href": "faqs.html#content-of-the-replication-package",
    "title": "Frequently Asked Questions",
    "section": "Content of the Replication Package",
    "text": "Content of the Replication Package\n\nWhat should be included in the replication package? Please see here.\nHow do I provide physical access to the replication team to my restricted-access data when I have been granted a data exemption?\n\n\nAnswer\n\nWhenever possible, the easiest way is to provide a physical copy of your data by including it in a separate folder labeled \"4 Confidential data not for publication\" outside of the replication package. All replicators and the Data Editor have signed confidentiality agreements that prevent them to use the data for any other purpose than the reproducibility checks. When that option is not feasible, we recommend you to contact our Data Editor to arrange the best way to provide access to the reproducibility team.\n\nWhat information should be included in the ReadMe file? Please see here.\nShould I submit the raw data files and the code that generates my final dataset from them?\n\n\nAnswer\n\nYes, this is requested by our Data and Code Availability Policy.\n\nWhy do I need to supply all text documents (ReadMe, IRB, etc.) in PDF format?\n\n\nAnswer\n\nThe PDF format is portable, which means that it can be transferred without having to worry about dependencies, fonts, etc. This ensures readability across platforms and users.\n\nWhy do I need to include a copy of all datasets in non-proprietary format (ASCII, csv, etc.)?\n\n\nAnswer\n\nSome users of your replication package may be not have access to the specific proprietary software that you used for your study. This ensures that they can have access to your data without problems. It also minimizes compatibility issues (e.g., old versions of Stata cannot open files saved by newer versions).",
    "crumbs": [
      "FAQs"
    ]
  },
  {
    "objectID": "faqs.html#data-citations",
    "href": "faqs.html#data-citations",
    "title": "Frequently Asked Questions",
    "section": "Data Citations",
    "text": "Data Citations\n\nWhat data should I cite?\n\n\nAnswer\n\nAll datasets used in the paper (with no exceptions) should be cited both in the paper and in a dedicated section of the ReadMe file.\n\nIf I mention my datasets in the Online Appendix or in the ReadMe file, should I cite them?\n\n\nAnswer\n\nYes, all datasets used in the paper (with no exceptions) should be listed in the references section of the paper in the same way that we cite other papers, and a copy of these citations should appear in a dedicated section of the ReadMe file.\n\nHow should I cite my data?\n\n\nAnswer\n\nYou should cite all datasets used in the paper (with no exceptions) in the references section of the paper in the same way that we cite other papers, and a copy of these citations should appear in a dedicated section of the ReadMe file. You can find some examples in page 7 of this document. More specific guidance on data citations is available here.\n\nWhy should I cite my data?\n\n\nAnswer\n\nData citations are as fundamental as citations to other papers, if not more. Giving proper credit to data providers is in line with all scientific ethical standards. Moreover, giving proper credit to data providers ensures that they can keep receiving external funding to make their datasets publicly available for research.",
    "crumbs": [
      "FAQs"
    ]
  },
  {
    "objectID": "faqs.html#reproducibility-certification-publication-of-the-replication-package-and-copyright-issues",
    "href": "faqs.html#reproducibility-certification-publication-of-the-replication-package-and-copyright-issues",
    "title": "Frequently Asked Questions",
    "section": "Reproducibility Certification, Publication of the Replication Package and Copyright Issues",
    "text": "Reproducibility Certification, Publication of the Replication Package and Copyright Issues\n\nWhat kind of certification do we provide for papers that were checked for reproducibility?\n\n\nAnswer\n\nThe empirical/simulation/experimental papers that we checked include the following statement: \"The data and codes for this paper are available at […]. They were checked for their ability to reproduce the results presented in the paper.\" This statement is adjusted accordingly when data exemptions are granted (acknowledging either that the authors provided temporary access to the confidential data or that the checks were implemented on simulated/synthetic data provided by the authors). In particular, we either certify \"The authors were granted an exemption to publish their data because access to the data is restricted. However, the authors provided a simulated or synthetic dataset that allowed the Journal to run their codes. The synthetic/simulated data and codes are available at […]. They were checked for their ability to generate all tables and figures in the paper, however, the synthetic/simulated data are not designed to reproduce the same results.\" or \"The authors were granted an exemption to publish their data because access to the data is restricted. However, the authors provided the Journal with temporary access to the data, which allowed the Journal to run their codes. The codes are available at […]. The data and codes were checked for their ability to reproduce the results presented in the paper.\", depending on the case that is applicable. These statements are combined accordingly when more than one situation applies. The statements are also also adjusted when the nature of the algorithms is highly demanding, and a partial/simplified version of the code has been used for the reproducibility checks: we add the sentence \"Given the highly demanding nature of the algorithms, the replication checks were run on a simplified version of the code, which is also available at […]\" to the applicable statement.\n\nWhere will the replication package be published?\n\n\nAnswer\n\nAfter all reproducibility checks are completed, you will be requested by the Journal Office to publish your checked package at the JPE’s dataverse. Dataverse will assing your package a Digital Object Identifier (DOI), which then will be linked with your publication.\n\nDo I keep the copyright of my package?\n\n\nAnswer\n\nYes, one of the main advantages of you publishing the package at the JPE’s dataverse is that you are the sole responsible and copyright owner of the specific publication. Therefore, it is important that you ensure that you have permission to publish your data before the time of first submission and request an exemption then if you don’t.\n\nWhy are packages published at the JPE’s community at dataverse instead of with the article on the Journal’s website?\n\n\nAnswer\n\nThere are many advantages from publishing the package at the JPE’s dataverse. Some of them are: (i) the author retains the copyright on the replication package, (ii) by having a specific DOI, it increases the visibility of all packages and, in turn, it increases the visibility of your article, and (iii) it makes it easier to cite.\n\nCan I post my replication material on other sites?\n\n\nAnswer\n\nYes, as long as one copy is published at the JPE’s community at dataverse. The only exception is when your replication package is published in a \"trusted\" repository (see the following list for guidance) with a permanent DOI. In that case, your DOI can be used to link your article with your package, and the Data Editor can wave the requirement to publish the package at the JPE’s community at dataverse. However, publishing your package at the JPE’s community at dataverse is recommended, because it increases the visibility of your package.\n\nAll data is publicly available. Do I still need to get permission from the website owner to post data on JPE’s publisher website?\n\n\nAnswer\n\nEach provider offers a different policy regarding re-distribution of original and transformed datasets. Some providers, for example, allow re-distribution as long as your extract is deposited in a specific repository. You should make sure about the restrictions to publish your data before the first submission. You should also make sure to seek permission from the original owner of the data to publish them, and make sure to cite the original source accordingly. You will be the responsible of copyright infringements for what you publish with the replication package at the JPE’s community at dataverse.",
    "crumbs": [
      "FAQs"
    ]
  },
  {
    "objectID": "policy.html",
    "href": "policy.html",
    "title": "JPE Data and Code Policy",
    "section": "",
    "text": "It is the policy of the Journal of Political Economy (JPE) to publish papers only if the data and computer code used in the analysis are clearly and precisely documented and are readily available to any researcher for purposes of replication (unless the exemptions discussed below apply). Authors of conditionally accepted papers, in particular those that contain empirical work, simulations, experimental work, or numerical computations, must provide, prior to publication, the data, programs, and other details of the computations sufficient to permit replication. They must also provide sufficient information to replicate the process of obtaining the raw data from the original sources and cite all the sources of data appropriately.\nThe JPE will perform reproducibility checks of empirical, experimental, and simulation results of all conditionally accepted papers and their approved online appendices. Eventual publication of the paper is conditional on a positive outcome of those checks. Requests for an exemption from providing the materials described in this policy, or for restricting their usage, should be stated clearly when the paper is first submitted for review. The handling editor will decide whether the paper should be reviewed in this case. Exceptions will not be considered later in the review and publication process.\nBy submitting to the JPE, authors indicate their acceptance of this Data and Code Policy.\nThe JPE endorses DCAS, the Data and Code Availability Standard [v1.0], and its data and code availability policy is compatible with DCAS.\nThe specific terms of the JPE Data and Code Policy are as follows.",
    "crumbs": [
      "Code and Data Policy"
    ]
  },
  {
    "objectID": "policy.html#data",
    "href": "policy.html#data",
    "title": "JPE Data and Code Policy",
    "section": "1 Data",
    "text": "1 Data\n\n1.1 Data Availability Statement\nA Data Availability Statement (DAS) must be provided with sufficient detail for independent researchers to replicate the necessary steps to access the original data, including information on any limitations and the expected monetary and time costs associated with data access. When applicable, the DAS should also specify the version of the dataset and the original date of access by the authors. Similarly, the DAS should clearly indicate which datasets are included and excluded from the replication package. The DAS should be included as a section of the README file (see Section 3.4 below).\n\n\n1.2 Raw Data\nThe raw data utilized in the research, including primary data collected by the author and secondary data, must be included in the replication package. If the exact extract of the raw data used in the analysis is published in a trusted repository that satisfies the FAIR data principles (guidance here), including a permanent identifier (e.g., its DOI) linking to these raw data is considered sufficient to fulfill the obligation of including the raw data in the replication package. In cases where legal barriers for sharing the data prohibit the authors from publishing them, the authors must request an exemption and provide a justification for not complying with the policy. When exemptions are granted, authors are required to comply with at least one of the following two procedures:\n\nWhenever possible, provide the JPE with temporary access to the data affected by the exemption for the purpose of implementing reproducibility checks. It is the authors’ responsibility to obtain permission from the data provider to confidentially share the data with the JPE.\nInclude in the replication package a synthetic or simulated dataset that enables users to execute the code and verify that it generates all outputs presented in the paper and appendices, even if the results differ from those in the paper. While including synthetic/simulated data is not required when temporary access for JPE is provided, it is still recommended, as it allows future users of the package to run the codes, increasing the publication’s impact.\n\nIn either of these two procedures, the authors are expected to clarify the nature of the exemption in the DAS (see Section 1.1).\n\n\n1.3 Analysis Data\nAnalysis Data is provided as part of the replication package unless they can be fully reproduced from accessible data within a reasonable time frame. Exceptions are to be explained in the DAS.\n\n\n1.4 Format\nThe data files must be either in plain ASCII format, such as comma-separated value (.csv), or any other non-proprietary format so that they can be read by any researcher on any machine. Additionally, the authors may choose to submit data in a format that is read by specific programs, such as Matlab (.mat) files, Stata (.dta), or Excel (.xlsx) files, but a copy of these files in a non-proprietary format is required in every case.\n\n\n1.5 Metadata\nA description of the variables included in the data and their allowed values must be made publicly accessible. Such a description could take the form of labels in the dataset, comments in the code, easy-to-identify variable names, codebooks, and indications in the README file.\n\n\n1.6 Citations\nAll data used in the paper and the approved online appendices must be appropriately cited in both the paper/appendices and in a dedicated references section of the README file. As a general guideline, citations of data employed in the paper should be included in the paper’s references section, while citations exclusively pertaining to data used in the approved online appendices may be relegated to the appendix. However, in exceptional circumstances, such as when there is a large number of data sources to cite or when recommended by the handling co-editor, citations of data used in the paper may be included in a references section of the approved appendix only.",
    "crumbs": [
      "Code and Data Policy"
    ]
  },
  {
    "objectID": "policy.html#code",
    "href": "policy.html#code",
    "title": "JPE Data and Code Policy",
    "section": "2 Code",
    "text": "2 Code\n\n2.1 Data Transformations\nAll programs used to generate final and analysis data sets from raw data must be included, even if the raw datasets cannot be provided due to approved exemptions to comply with Section 1.2 above. Whenever transformations or simulations include randomly generated numbers, the code must ensure reproducibility with appropriate means (e.g., setting a seed for the random number generator).\n\n\n2.2 Analysis Code\nPrograms that produce any kind of computational results (e.g., estimation, simulation, model solution, visualization, etc.) must be included. These programs should produce all such computational exhibits in the paper and approved online appendices (i.e., tables, figures, in-text numbers) with minimal human intervention.\nIn cases where execution times of the programs are excessively long, authors are encouraged to provide simplified versions of their programs that allow partial reproduction of results in a reasonable time frame. Similarly, authors of such computationally intensive papers are encouraged to include intermediate results in the replication package, such that reproducibility checks can be performed, taking those results as given. Note that this does not invalidate the requirement to provide code that reproduces all output without relying on intermediate results. In such cases, authors are required to collaborate with the Data Editor to develop a feasible strategy for reproducibility checks. The extent of the eventual partial reproducibility checks must be clearly documented in the package README.\n\n\n2.3 Format of Code\nCodes must be provided in source format which can be directly interpreted or compiled by appropriate software. Single-driver scripts that run all of the code from raw data to final results are strongly encouraged and must be provided at the Data Editor’s specific request (e.g., to limit the number of human intervention steps). The code must save all exhibits (e.g., tables and figures) appearing in the paper and appendices in a specified directory within the replication package. When the codes are written in compiled languages, precise instructions for all steps and compiling options must be included in the documentation. A make file (or similar build tool) that reproduces compilation steps is strongly encouraged. In general, all necessary steps to recreate a stable computational environment should be taken (such as, e.g., precise specification of software and library versions, virtual environments, and containerization). Software that does not allow generating output using scripts (e.g., ArcGIS or MS Excel) is discouraged. When this type of software is used, very precise step-by-step instructions allowing users to exactly reproduce the generated outputs independently of the authors must be included in the README file.",
    "crumbs": [
      "Code and Data Policy"
    ]
  },
  {
    "objectID": "policy.html#supporting-materials",
    "href": "policy.html#supporting-materials",
    "title": "JPE Data and Code Policy",
    "section": "3 Supporting Materials",
    "text": "3 Supporting Materials\n\n3.1 Survey Instruments and Experimental Instructions\n\nMaterial Expected in Replication Package\nIn case the raw data are collected or generated via surveys or experiments, authors are required to include survey instruments or experimental instructions and subject selection criteria in the replication package. Specifically, it is required that the entirety of the following information be included in the package README, regardless of whether some of it appears in the paper or the appendix already:\n\nThe subject pool and recruiting procedures.\nThe experimental technology – when and where the experiments were conducted; by computer or manually; online, and so forth.\nAny procedures to test for comprehension before running the experiment, including the use of practice trials and quizzes.\nMatching procedures, especially for game theory experiments.\nSubject payments, including whether artificial currency was used, the exchange rate, show-up fees, average earnings, lotteries, and/or grades.\nThe number of subjects used in each session and, where relevant, their experience.\nTiming, such as how long a typical session lasted, and how much of that time was instructional.\nAny use of deception and/or any instructional inaccuracies.\nDetailed statement of protocols.\nSamples of permission forms and record sheets.\nCopies of instructions and slides/transparencies used to present instructions.\nSource code for computer programs used to conduct the experiment and to analyze the data. This does not include compilers (such as zTree) that are publicly available.\nScreen shots showing how the programs are used.\n\nThe documentation provided in the replication package must be self-contained, regardless of the content included in the paper and approved online appendices, as the replication package is a different citable object than the paper. As a general rule, the replication package must be at least as exhaustive as the paper and approved appendices, since there are no space constraints in the documentation provided in the replication package.\n\n\nInitial Submission of Experimental Papers\nSimilarly to requests about exemptions from the Data and Code Policy, authors should include as much information about their experimental procedure as possible in their initial submission. All the materials listed above are desirable and typically expected, but further details about what is needed in each case can be obtained from the co-editor handling the paper. If, during the review process, the editor or referees feel additional information is needed, requests for that material will be made and may naturally cause a delay in processing. Hence, we encourage as complete a submission as feasible.\n\n\n\n3.2 Ethics\nAuthors who collect primary data (e.g., via experiment or survey) are required to include the IRB approval documentation (or similar) from their institution.\n\n\n3.3 Pre-registration\nIf applicable, pre-registration of the research project must be documented in the README.\n\n\n3.4 Documentation in README file\nA README document in either pdf or markdown format has to be included in the replication package. The file README.pdf or README.md must be located at the root of the replication package, it must contain all information required to reproduce the results (there should not be multiple locations for documentation). As a minimal requirement, the README should contain at least the following items:\n\nA DAS as explained in Section 1.1\nA description of the content of the replication package.\nPrecise instructions on all the steps required to run the code to reproduce all exhibits included in the paper and appendices.\nPrecise instructions on where in the replication package the produced outputs will be saved, and how each of them maps to the exhibits included in the paper and appendices.\nPrecise specifications of software and hardware used by the authors when preparing the package, including expected running time and specific requirements needed to successfully reproduce the results (e.g., software versions, libraries to be installed, etc.). When the requirements and execution time are heterogeneous across significant portions of the package, specific requirements and running times for each of the different parts must be indicated.\nData citations, according to Section 1.6.\n\nIt is strongly recommended to use the README template (available here) of the Social Sciences Data Editors.",
    "crumbs": [
      "Code and Data Policy"
    ]
  },
  {
    "objectID": "policy.html#sharing",
    "href": "policy.html#sharing",
    "title": "JPE Data and Code Policy",
    "section": "4 Sharing",
    "text": "4 Sharing\n\n4.1 Location\nReplication packages for conditionally accepted papers are reviewed by the Data Editor. After the successful conclusion of reproducibility checks, the authors upload the package to the JPE dataverse repository.\nIn cases where data cannot be published in an openly accessible trusted data repository like the JPE dataverse, authors who have requested an exemption to publish them at the time of first submission must commit to preserving the data and code for a period of no less than five years following the publication of the paper. They should also provide reasonable assistance to requests for clarification and replication.\n\n\n4.2 License\nThe replication package must be deposited with a license that specifies the terms of use of the code and data in the replication package. The license must, at the very least, allow for unrestricted access to all files included in the deposit and permit the usage of the package for replication purposes by researchers unconnected to the original parties.\n\n\n4.3 Omissions\nThe README must clearly indicate any omission of the required parts of the package as a result of a granted exemption. The README must also indicate the reasons for such omission, such as legal requirements, limitations, or other approved agreements. In cases where the extent or complexity of the reproducibility checks impedes the exact reproduction of all the results in the paper and approved appendices, such as when synthetic datasets are provided (see Section 1.2) or partial checks have been implemented (see Section 2.2), the README must clarify which results have not been checked for reproducibility and why.\n\nVersion v1, June 30, 2025",
    "crumbs": [
      "Code and Data Policy"
    ]
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog",
    "section": "",
    "text": "STATA Versioning\n\n\n\nSTATA\n\n\nversions\n\n\npackages\n\n\n\nChallenges when reproducing results with different versions of STATA\n\n\n\nFlorian Oswald\n\n\nJun 30, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "best.html",
    "href": "best.html",
    "title": "Best Practices for Replication Packages",
    "section": "",
    "text": "Data Editor Collaboration\n\n\n\nThe Data Editors of several economics journals collaborate to produce overall unofficial common guidance, which we recommend to consult.\nThere is a set of practices that are strongly recommended for all replication packages. The following list includes some of them:",
    "crumbs": [
      "Best Practice"
    ]
  },
  {
    "objectID": "best.html#folder-structure",
    "href": "best.html#folder-structure",
    "title": "Best Practices for Replication Packages",
    "section": "Folder Structure",
    "text": "Folder Structure\n\nWe are aware that research happens in haphazard ways sometimes, without any time to waste on seemingly irrelevant housekeeping tasks. We encourage you nevertheless to try and impose a rigid folder structure on your research project from day one, when concerns about a replication package might still be far away - some folder could even remain empty for a while, but that’s ok! You will save a lot of time later on. Here are two examples:\n\n\n\n\nGood.\n\nMeaningful sub directories\ntop level README\ncode/data/output are separated\n\n.\n├── README.md\n├── code\n│   ├── R\n│   │   ├── 0-install.R\n│   │   ├── 1-main.R\n│   │   ├── 2-figure2.R\n│   │   └── 3-table2.R\n│   ├── stata\n│   │   ├── 1-main.do\n│   │   ├── 2-read_raw.do\n│   │   ├── 3-figure1.do\n│   │   ├── 4-figure2.do\n│   │   └── 5-table1.do\n│   └── tex\n│       ├── appendix.tex\n│       └── main.tex\n├── data\n│   ├── processed\n│   └── raw\n└── output\n    ├── plots\n    └── tables\nNotice how this example includes tex/main.tex which will produce the final product. The code folder would contain all the source code needed to produce everything in the paper, and could be placed under version control. Notice also that the content of output/ could be erased without problems - all required inputs are separated and could regenerate all results immediately.\n\n\n\n\n\nNot So Good.\n\nSub directories are not helpful\nFile names are confusing\nno README\ncode/data/output are not separated\n\n.\n├── 20211107ext_2v1.do\n├── 20220120ext_2v1.do\n├── 20221101wave1.dta\n├── james\n│   └── NLSY97\n│       └── nlsy97_v2.do\n├── mary\n│   └── NLSY97\n│       └── nlsy97.do\n├── matlab_fortran\n│   ├── graphs\n│   ├── sensitivity1\n│   │   ├── data.xlsx\n│   │   ├── good_version.do\n│   │   └── script.m\n│   └── sensitivity2\n│       ├── models.f90\n│       ├── models.mod\n│       └── nrtype.f90\n├── readme.do\n├── scatter1.eps\n├── scatter1_1.eps\n├── scatter1_2.eps\n├── ts.eps\n├── wave1.dta\n└── wave2.dta\n└── wave2regs.dta\n└── wave2regs2.dta",
    "crumbs": [
      "Best Practice"
    ]
  },
  {
    "objectID": "best.html#data",
    "href": "best.html#data",
    "title": "Best Practices for Replication Packages",
    "section": "Data",
    "text": "Data\n\nAlways keep your raw data intact (i.e. read-only). Generate separate analysis datasets to perform analysis. After you copied your raw data into the package (rawdata folder), set to read only. Look here for windows tips to set read-only, on *nix systems it’s a\nchmod 444 rawdata\nDatasets change over time, keep a record of the date and versions you obtained. It might be difficult to obtain it in the future.",
    "crumbs": [
      "Best Practice"
    ]
  },
  {
    "objectID": "best.html#code",
    "href": "best.html#code",
    "title": "Best Practices for Replication Packages",
    "section": "Code",
    "text": "Code\n\nGenerate your analysis data using programs, many journals require you to submit them.\nSeparate code, data and outputs in your directory structure. This will facilitate (i) keeping versions of your code, and (ii) producing a replication package.\nStronlgy consider the benefits of version control for the reproducibility of your research. Click here for a tutorial.\nUse programs/scripts as opposed to command-line instructions!\nDesign your code to be run all at once, and not section by section. Create a master file that calls all other subsidiary files.\nSet the paths only once and at the top of the master-file, and then use either relative paths or global variables, so that users don’t have to change the paths in multiple parts of your code.\nWhenever possible, write paths in a way that is compatible across different operating systems. For example, in Stata, always use forward slashes / to separate directories, even if you use Windows.\nIf you are using software which requires compilation of source code into executables (e.g. Fortran, C, etc.), please use make files (or else make sure you provide very detailed instructions on how to compile the different files - we accept bash shell scripts).\nName your files in a wise manner. For example, if your output generates tables and figures as new files, give them names that easily identify them. Also, name your master file as “Main”, “Master” or something similar.\nUse sub-folders when your package includes a lot of files. Make sure that your package includes all relevant folders, even empty folders that will be filled with the outputs from the program.",
    "crumbs": [
      "Best Practice"
    ]
  },
  {
    "objectID": "best.html#output",
    "href": "best.html#output",
    "title": "Best Practices for Replication Packages",
    "section": "Output",
    "text": "Output\n\nUse log-files and write to disk. Make sure that your code stores the output (both tables and figures) as files on disk (in subdirectory outputs/) as opposed to only showing it on screen while you are executing it.\nMake your code produce all tables and figures as they appear in the manuscript: you will save a lot of time! We recommend splitting your code into small subunits, each of which produce a dedicated output, for instance a function figure1() which would produce and save the file outputs/figure1.pdf in your package, where outputs/figure1.pdf is included via \\input{outputs/figure1.pdf} in the \\(\\LaTeX\\) source code of your paper as as Figure 1! Of course the same holds for tables and other output. You could then include the following table in your README, greatly helping our replicators (and yourself 😉):\n\n\n\nOutput in Paper\nOutput in Package\nScript/Program to execute\n\n\n\n\nTable 1\noutputs/tables/table1.tex\ncode/table1.do\n\n\nFigure 1\noutputs/plots/figure1.pdf\ncode/figure1.do\n\n\nFigure 2\noutputs/plots/figure2.pdf\ncode/figure2.do\n\n\n\nRun your codes from the replication folder before you submit and make sure it runs and all your results are reproduced - ideally on another machine!\nMake sure to delete all expected output from the package before you run it, so you can be sure that all output was actually produced.\nIdeally, your submitted paper (your \\(\\LaTeX\\) file which produces it) should depend on the output of your replication package, so that if a piece of output is missing, the paper cannot be compiled (or you would quickly spot the mistake).\nHelp us by submitting your package without any expected output, i.e. with an empty folder outputs/.",
    "crumbs": [
      "Best Practice"
    ]
  }
]